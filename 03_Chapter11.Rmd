# Chapter 11 {-}
<p class="h-large">Inferences  About  Population  Variances</p>![](./artwork/03.jpg)


## Ch 11 Notation & Definitions {-}

The **standard deviation** and the **variance** are measures of
variability. They measure how much the values of a variable in a given
sample or population vary above and below the mean. A population or
sample with values that are closer to the mean would have a lower
variance and a lower standard deviation than a population or sample with
values more spread out around the mean.

| Population Parameters |  | Sample Statistics |  |
|:--:|------|:--:|------|
| $\sigma$ | standard deviation of a population <br> the lowercase Greek letter "sigma" | $s$ | standard deviation of a sample |
| $\sigma^2$ | variance of a population <br> "sigma squared" | $s^2$ | variance of a sample |


The **standard deviation** is the **square root** of the **variance**:
$\sigma = \sqrt{\sigma^2}\ and\ s = \sqrt{s^2}.$

Likewise, the **variance** is the **standard deviation squared**,
exactly how it appears in the notation.

<br>

:::example

**Example**

If the standard deviation of a sample is 12, what is the  variance of the sample?                                              
                                              
We are given that $s$ = 12.
The sample variance is $s^2$, so we can calculate the variance: $s^2=12^2=144$.
Thus, the variance of the sample is 144 and is denoted with $s^2$.
:::

**NOTE:** problem descriptions could refer to either a variance OR a
standard deviation. You must treat them accordingly in the equations for
this chapter. If you notate the values properly, then you will know when
a value needs to be squared and when it does not.

<br>

Each of these letters can be subscripted to refer to specific
populations and samples, like this:

|  | Population Parameters with subscripts |  | Sample Statistics with subscripts |
|:-----:|------------------------------|:-----:|--------------------------|
| $\sigma_{1}$ | standard deviation of population 1 | $s_{1}$ | standard deviation of sample 1 <br> (from population 1) |
| $\sigma_{2}$ | standard deviation of population 2 | $s_{2}$ | standard deviation of sample 2 <br> (from population 2) |
| $\sigma_{1}^{2}$ | variance of population 1 | $s_{1}^{2}$ | variance of sample 1 <br> (from population 1) |
| $\sigma_{2}^{2}$ | variance of population 2 | $s_{2}^{2}$ | variance of sample 2 <br> (from population 2) |

<br>

This chapter will introduce two new test statistics, with corresponding
sampling distributions and a host of critical values. The notation we
will use is:

| **Chi-Square $\mathbf{\chi^2}$** |  |
|:---------:|-------------------------|
| $\chi^2$ | This is the Greek letter "chi" squared. <br> Pronounced "kai square" |
| $\chi_{test}^2$ | A chi-square test statistic |
| $\chi_{\alpha,LT}^2$ | A critical value of chi-square at $\alpha$ in the lower tail. <br> The critical value in a  **lower-tail** test with a <br>  $\chi^{2}$ **test statistic.** |
| $\chi_{\alpha,UT}^2$ | A critical value of chi-square at $\alpha$ in the upper tail. <br> The critical value in an **upper-tail** test with a <br>  $\chi^{2}$ **test statistic.** |
| $\chi_{\alpha/2,LT}^2$ | A critical value of chi-square at $\alpha/2$ in the lower tail. <br> The **lower tail critical value** in a **two-tailed** test <br>  with a $\chi^{2}$ **test statistic.** |
| $\chi_{\alpha/2,UT}^2$ | A critical value of chi-square at $\alpha/2$ in the upper tail. <br> The **upper tail critical value** in a **two-tailed** test <br> with a $\chi^{2}$ **test statistic.** |

<br>
<br>

| $\mathbf{F}$ |  |
|:---------:|-------------------------|
| $F_{test}$ | An $F$ test statistic |
| $F_{\alpha}$ | An upper-tail critical value of $F$ at $\alpha$. <br> The critical value in an **upper-tail** test <br> with an $F$ **test statistic.** |
| $F_{\alpha/2}$ | A two-tailed critical value of $F$ at $\alpha/2$. <br> The critical value in a **two-tailed** test <br> with an $F$ **test statistic.** |


## Hypothesis Tests about a Single Population Variance {-}

### 1. Formulating the Hypotheses {-} 
There are three possible forms of hypotheses. They each correspond to a different
question you might want to ask about the true value of the
population variance, $\sigma^2.$

**Note:** in each of the hypotheses, $\sigma_0^2$ is a number. It is a value that $\sigma^2$ is hypothesized to be.

<br>

<center> **Hypotheses for Hypothesis Tests about a Single Population Variance,** $\mathbf{\sigma^2}$ 
</center>

| **Lower Tail Test** | **Upper Tail Test** | **Two-Tailed Test** |
|:-------------------:|:-------------------:|:-------------------:|
| $H_0:\sigma^2 \geq \sigma_0^2$ <br> $H_0:\sigma^2 < \sigma_0^2$ | $H_0:\sigma^2 \leq \sigma_0^2$ <br> $H_0:\sigma^2 > \sigma_0^2$ | $H_0:\sigma^2 = \sigma_0^2$ <br> $H_0:\sigma^2 \neq \sigma_0^2$ |
|  | Answers questions about |  |
| If the true population variance, $\sigma^2$, is less than a given number, $\sigma_0^2$ | If the true population variance, $\sigma^2$, is greater than a given number, $\sigma_0^2$ | If the true population variance, $\sigma^2$, is different from a given number, $\sigma_0^2$ |

<br>

Upper Tail and Lower Tail Tests are called **one-tailed** or
**directional** tests. Two-tailed tests are called **non-directional**
tests.

### 2. Calculating the Test Statistics {-}

Under the assumption that $H_0$ is true as an equality, the sampling
distribution of the sample variance, $s^2$, follows the ch-square
$(\chi^2)$ distribution. Therefore, we standardize our sample against the $\chi^2$
distribution by calculating the following $\chi_{test}^2$
test statistic:

<br>

$$\chi_{test}^2 = \frac{\left( n - 1 \right)s^2}{\sigma_0^2}$$

where
<center>
$s^2$ = the sample variance (or the sample standard deviation squared)  
$\sigma_0^2$ = the hypothesized population variance (from the hypotheses)    
$n$ = the sample size  
and the degrees of freedom are $df = n - 1$  
</center>
<br>

**NOTE:** some problems will give you the variances
($s^2$ and $\sigma_0^2$, in which case you simply plug
the values into the equation as is. However, some problems will give
you standard deviations ($s$ and $\sigma_0$), in which case
you would need to square those values in this equation.


### 3.  Deciding whether or not to reject $\mathbf{H_0}$ {-}

There are two approaches to deciding whether or not to reject the Null:

-   In the **p-value approach**, we **compare** the **p-value** of our
    test statistic to the $\alpha$ **significance level** and
    reject $H_0$ if the p-value is less than or equal to the $\alpha$
    significance level.

-   In the **critical value approach**, we **compare** the **test
    statistic** to **a critical value** - this can be done with a
    diagram in which we use the critical value(s) to construct a
    rejection region or regions; if the test statistic is in a rejection
    region, we reject $H_0$ and accept $H_A.$ Or, this step can be
    accomplished by following the mathematical rules given in the tables
    below.

**REMINDER:** you can never *accept* the null hypothesis. Remember the
swans.

<br>

<center> **When to Reject $\mathbf{H_0}$ for Chi-square ($\mathbf{\chi^2}$) Test Statistics**
</center>

|  | **For a Lower Tail Test** | **For an Upper Tail Test** | **For a Two-Tail Test** |
|:-:|---------------------------|----------------------------|-------------------------|
| **p-value approach** | Calculate the lower tail p-value of $\chi_{test}^2$ <br><br> If the LT p-value$\leq$ $\alpha$, then reject $H_0$ and accept $H_A$. <br><br> If the LT p-value> $\alpha$, then do not reject $H_0$. $H_A$ is unsupported. | Calculate the upper tail p-value of $\chi_{test}^2$ <br><br> If the UT p-value $\leq$ $\alpha$, then reject $H_0$ and accept $H_A$. <br><br> If the UT p-value > $\alpha$, then do not reject $H_0$. $H_A$ is unsupported. | The two-tailed p-value is two times the one-tailed p-value of $\chi_{test}^2$. <br><br> If the 2T p-value $\leq$ $\alpha$, then reject $H_0$ and accept $H_A$. <br><br> If the 2T p-value > $\alpha$, then do not reject $H_0$. $H_A$ is unsupported. |
| **CV approach** | If $\chi_{test}^2$ $\leq$ $\chi_{\alpha,LT}^2$, then reject $H_0$  and accept $H_A$ <br> <br> If $\chi_{test}^2$ > $\chi_{\alpha,LT}^2$, then do not reject $H_0$. $H_A$ is unsupported. | If $\chi_{test}^2$ $\geq$ $\chi_{\alpha,UT}^2$, then reject $H_0$ and accept $H_A$ <br><br> If $\chi_{test}^2$ < $\chi_{\alpha,UT}^2$, then do not reject $H_0$. $H_A$ is unsupported. | If $\chi_{test}^2$ $\leq$ $\chi_{\alpha/2,LT}^2$  OR <br> $\chi_{test}^2$ $\geq$ $\chi_{\alpha/2,UT}^2$, then reject $H_0$ and accept $H_A$. <br><br> If $\chi_{\alpha/2,LT}^2$ < $\chi_{test}^2$ < $\chi_{\alpha/2,UT}^2$ then do not reject $H_0$.$H_A$ is unsupported. |

**NOTES:**  
1. $\chi_{test}^2$ is a Test Statistic  
2. $\chi_{\alpha,LT}^2$, $\chi_{\alpha,UT}^2$, $\chi_{\alpha/2,LT}^2$, $\chi_{\alpha/2,UT}^2$ are Critical Values
3. $\chi^2$ is based on degrees of freedom. Be sure to calculate the appropriate degrees of freedom for the test you are performing.
  
<br>

### 4.  Interpreting the Test {-}

(Note: This explanation of interpretation holds for ALL hypothesis
tests.) We start every hypothesis test with a question about the
parameter of interest, so we must end every hypothesis test with the
answer to that question. In other words, we must *interpret* the
conclusion of our test in terms of the original question.

Remember: in hypothesis testing you can never prove the null
hypothesis. You can only prove the alternative hypothesis: when you
reject the null and accept the alternative, then at your given
$\alpha$ level of significance you may conclude that $H_A$ is true.
If you do not reject $H_0$, then you must conclude that $H_A$ is
unsupported by the evidence. This gives us a clear guideline for how
to *interpret* hypothesis tests: *always look at the alternative
hypothesis!*

In all that follows, you would substitute the actual words and numbers
from your hypothesis test for the symbols. Notice that each
interpretation simply states the alternative hypothesis in words, and
says either that it is true or that we cannot conclude that it is
true.

<br>

<center> **How to Interpret a Hypothesis Test about a Single Population Variance, $\mathbf{\sigma^2}$**
</center>

| **When you** | **For a Lower Tail Test** | **For an Upper Tail Test** | **For a Two-Tailed Test** |
|:-:|----|----|----|
| **Reject $\mathbf{H_0}$** | At the α significance level, we can conclude that $\sigma^2$  is less than $\sigma_0^2$. | At the α significance level, we can conclude that $\sigma^2$  is greater than $\sigma_0^2$. |  At the α significance level, we can conclude that $\sigma^2$  is different than $\sigma_0^2$. |
**Do not reject $\mathbf{H_0}$** | At the α significance level, we cannot conclude that $\sigma^2$  is less than $\sigma_0^2$. | At the α significance level, we cannot conclude that $\sigma^2$  is greater than $\sigma_0^2$. | At the α significance level, we cannot conclude that $\sigma^2$  is different than $\sigma_0^2$.
    
    
**NOTES:**    
1. $\sigma^2$ is the true value of the population variance  
2. $\sigma_0^2$ is a number that is the hypothesized value of $\sigma^2$

### Assumptions Underlying Hypothesis Tests about the Difference between Two Population Means {-}

All hypothesis tests use sampling distributions to determine the
probability of sample statistics. In order for us to be confident that
our choice of sampling distribution for any given test really is the way
the sample statistic is distributed, certain assumptions must be met. If
the assumptions are not met - that is, if any given assumption is not
true - then we cannot rely on the results of the hypothesis tests. They
may mislead us, give us the wrong answers, and cause us to draw the
wrong conclusions.

When making inferences about a single population variance using
$\chi^2$:

-  The underlying population must be normally distributed. If it is not
   normal, then the sampling distribution is unknown, so we cannot use
   $\chi^2$ as the sampling distribution.

-  The sample must be random. If it is not random, then the sampling
   distribution is unknown, so we cannot use $\chi^2$as the sampling
   distribution.

<br>

## Hypothesis Tests about Two Population Variances {-}

### 1. Formulating the Hypotheses {-}

There are two possible forms of hypotheses: upper tail and two-tailed. Whenever a
directional question is asked (that is, a less-than or greater-than
question), we will formulate the hypothesis test as an upper tail
test. The two forms correspond to different questions you might want
to ask about the true values of two population variances,
$\sigma_1^2$ and $\sigma_2^2$.

**Note:** in each hypothesis,  <center>
$\sigma_1^2$ = the variance of population 1, and  
$\sigma_2^2$ = the variance of population 2
</center>

<br>

<center> **Hypotheses for Hypothesis Tests about Two Population Variances, $\sigma_1^2$  and $\sigma_2^2$**
</center>

| **Upper Tail Test** | **Two-Tailed Test** |
|:-------------------:|:-------------------:|
| $H_0$: $\sigma_1^2$ $\leq$ $\sigma_2^2$ <br> $H_A$: $\sigma_1^2$ $>$ $\sigma_2^2$ | $H_0$: $\sigma_1^2$ $=$ $\sigma_2^2$ <br> $H_A$: $\sigma_1^2$ $\neq$ $\sigma_2^2$ |
| Answers questions about | Answers questions about |
| If the true population variance of population 1, $\sigma_1^2$, is greater than the true population variance of population 2, $\sigma_2^2$. <br> <br> **NOTE:** This test also tells you if the variance of population 2, $\sigma_2^2$, is less than the variance of population 1, $\sigma_1^2$. | If the true population variance of population 1, $\sigma_1^2$, is different from the true population variance of population 2, $\sigma_2^2$. |

<br>
The Upper Tail Test is a **one-tailed** or **directional** test.
Two-tailed tests are called **non-directional** tests.


### 2. Calculating the Test Statistics {-}

To properly formulate the test statistic, you MUST use **the larger sample variance as $s_1^2$ and the smaller sample variance as $s_2^2$**.
You can use this information to label the populations: the sample with
the larger sample variance is sample 1 from Population 1, and the
sample with the smaller variance is sample 2 from Population 2. By
doing this, you will ensure that the test statistic is in the upper
tail of the F distribution, and the critical values on the F table
will work properly.

For hypothesis testing about two population variances, the sample
statistics of interest are the sample variances,
$s_1^2$ and $s_2^2$. Under the assumption that $H_0$
is true as an equality, the sampling distribution of the ratio of the
sample variances follows the F distribution. Therefore, we standardize
our samples against the F distribution by calculating the following F
test statistic:

$$F_{test} = \frac{s_1^2}{s_2^2} $$
with <center>
Numerator degrees of freedom: $df_1 = n_1 -1$  
Denominator degrees of freedom: $df_2 = n_2 - 1$
</center>  
where <center>  
$s_1^2$ = the sample variance of sample 1  
$s_2^2$ = the sample variance of sample 2  
$n_1$ = the sample size of sample 1
$n_2$ = the sample size of sample 2  
</center>

<br>

**NOTE:** some problems will give you the variances
($s_1^2$ and $s_2^2$, in which case you simply plug
the values into the equation as is. However, some problems will give
you standard deviations ($s_1$ and $s_2$), in which case
you would need to square those values in this equation.

### 3.  Deciding whether or not to reject $\mathbf{H_0}$ {-}


There are two approaches to deciding whether or not to reject the Null:

-   In the **p-value approach**, we **compare** the **p-value** of our
    test statistic to the $\alpha$ **significance level** and
    reject $H_0$ if the p-value is less than or equal to the $\alpha$
    significance level.

-   In the **critical value approach**, we **compare** the **test
    statistic** to **a critical value** -- this can be done with a
    diagram in which we use the critical value(s) to construct a
    rejection region or regions; if the test statistic is in a rejection
    region, we reject $H_{0}$ and accept $H_{A}.$ Or, this step can be
    accomplished by following the mathematical rules given in the tables
    below.

REMINDER: you can never *accept* the null hypothesis. Remember the
swans.

<br>

<center> **When to Reject $\mathbf{H_0}$ if the Test Statistic is $\mathbf{F}$**
</center>

|  | **For a Lower Tail Test** | **For an Upper Tail Test** | 
|:-:|---------------------------|----------------------------|
| **p-value approach** | Calculate the upper tail p-value of $F_{test}$ <br><br> If the UT p-value ≤ $\alpha$, then reject $H_0$ and accept $H_A$. <br><br> If the UT p-value > $\alpha$, then do not reject $H_0$.$H_A$  is unsupported. | The two-tailed p-value of $F_{test}$ is <br><br> 2 x upper tail p-value of $F_{test}$ <br><br> If the 2T p-value ≤ $\alpha$, then reject $H_0$ and accept $H_A$. <br><br> If the 2T p-value > $\alpha$, then do not reject $H_0$. $H_A$  is unsupported.|
| **CV approach** | If $F_{test}$≥F_$\alpha$, then reject $H_0$ and accept $H_A$. <br><br> If $F_{test}$ < F_$\alpha$, then do not reject $H_0$. $H_A$  is unsupported. <br><br> | If $F_{test}$ ≥ F_($\alpha$/2), then reject $H_0$ and accept $H_A$. <br><br> If $F_{test}$ < F_($\alpha$/2), then do not reject $H_0$.  $H_A$  is unsupported.
 | 


**NOTES:**  
1. $F_{test}$ is a Test Statistic  
2. $F_{\alpha}$, and $F_{\alpha/2}$ are Critical Values
3. The degrees of freedom are numerator $df_1 = n_1 - 1$ and denominator $df_2 = n_2 - 1$



### 4. Interpreting the Test {-}

(Note: This explanation of interpretation holds for ALL hypothesis
tests.) We start every hypothesis test with a question about the
parameter of interest, so we must end every hypothesis test with the
answer to that question. In other words, we must *interpret* the
conclusion of our test in terms of the original question.

Remember: in hypothesis testing you can never prove the null
hypothesis. You can only prove the alternative hypothesis: when you
reject the null and accept the alternative, then at your given
$\alpha$ level of significance you may conclude that $H_{A}$ is true.
If you do not reject $H_{0},\ $then you must conclude that $H_{A}$ is
unsupported by the evidence. This gives us a clear guideline for how
to *interpret* hypothesis tests: *always look at the alternative
hypothesis!*

In all that follows, you would substitute the actual words and numbers
from your hypothesis test for the symbols. Notice that each
interpretation simply states the alternative hypothesis in words, and
says either that it is true or that we cannot conclude that it is
true.

<br>



+----------------------+----------------------+----------------------+
| **How to Interpret a |                      |                      |
| Hypothesis Test      |                      |                      |
| about Two Population |                      |                      |
| Variances,**         |                      |                      |
| $\m                  |                      |                      |
| athbf{\sigma}_{\math |                      |                      |
| bf{1}}^{2}\ |                      |                      |
| mathbf{\text{\ and\  |                      |                      |
| }}\sigma_{\ |                      |                      |
| mathbf{2}}^{\mathbf{ |                      |                      |
| 2}}\mathbf{\ }$**:** |                      |                      |
+======================+======================+======================+
| **When you:**        | **For an Upper Tail  | **For a Two-Tailed   |
|                      | Test:**              | Test:**              |
+----------------------+----------------------+----------------------+
| **Reject**           | This result can be   | At the               |
| $\mat                | interpreted two      | $\te                 |
| hbf{H}_{\mathbf{0}}$ | ways. Choose the     | xt{α\ }$significance |
|                      | interpretation that  | level, we can        |
|                      | is appropriate in    | conclude that        |
|                      | the context of the   | $\sigma_{1}^{2}\ $is |
|                      | problem:             | different than       |
|                      |                      | $\sigma_{2}^{2}$.    |
|                      | 1)  At the           |                      |
|                      |     $\te             |                      |
|                      | xt{α\ }$significance |                      |
|                      |     level, we can    |                      |
|                      |     conclude that    |                      |
|                      |     $\mathb          |                      |
|                      | f{\sigma}_{\mathbf{1 |                      |
|                      | }}^{2}\ $is |                      |
|                      |     **greater** than |                      |
|                      |     $\ma             |                      |
|                      | thbf{\sigma}_{\mathb |                      |
|                      | f{2}}^{2}$. |                      |
|                      |                      |                      |
|                      | 2)  At the           |                      |
|                      |     $\te             |                      |
|                      | xt{α\ }$significance |                      |
|                      |     level, we can    |                      |
|                      |     conclude that    |                      |
|                      |     $\mathb          |                      |
|                      | f{\sigma}_{\mathbf{2 |                      |
|                      | }}^{2}\ $is |                      |
|                      |     **less** than    |                      |
|                      |     $\ma             |                      |
|                      | thbf{\sigma}_{\mathb |                      |
|                      | f{1}}^{2}$. |                      |
+----------------------+----------------------+----------------------+
| **Do not reject**    | This result can be   | At the               |
| $\mat                | interpreted two      | $\te                 |
| hbf{H}_{\mathbf{0}}$ | ways. Choose the     | xt{α\ }$significance |
|                      | interpretation that  | level, we cannot     |
|                      | is appropriate in    | conclude that        |
|                      | the context of the   | $\sigma_{1}^{2}\ $is |
|                      | problem:             | different than       |
|                      |                      | $\sigma_{2}^{2}$.    |
|                      | 1)  At the           |                      |
|                      |     $\te             |                      |
|                      | xt{α\ }$significance |                      |
|                      |     level, we cannot |                      |
|                      |     conclude that    |                      |
|                      |     $\mathb          |                      |
|                      | f{\sigma}_{\mathbf{1 |                      |
|                      | }}^{2}\ $is |                      |
|                      |     **greater** than |                      |
|                      |     $\ma             |                      |
|                      | thbf{\sigma}_{\mathb |                      |
|                      | f{2}}^{2}$. |                      |
|                      |                      |                      |
|                      | 2)  At the           |                      |
|                      |     $\te             |                      |
|                      | xt{α\ }$significance |                      |
|                      |     level, we cannot |                      |
|                      |     conclude that    |                      |
|                      |     $\mathb          |                      |
|                      | f{\sigma}_{\mathbf{2 |                      |
|                      | }}^{2}\ $is |                      |
|                      |     **less** than    |                      |
|                      |     $\ma             |                      |
|                      | thbf{\sigma}_{\mathb |                      |
|                      | f{1}}^{2}$. |                      |
+----------------------+----------------------+----------------------+
| NOTES:               |                      |                      |
|                      |                      |                      |
| 1)                   |                      |                      |
| $\sigma_{1}^{2}\ $is |                      |                      |
|     the true         |                      |                      |
|     variance of      |                      |                      |
|     population 1;    |                      |                      |
|                      |                      |                      |
| $\sigma_{2}^{2}\ $is |                      |                      |
|     the true         |                      |                      |
|     variance of      |                      |                      |
|     population 2     |                      |                      |
+----------------------+----------------------+----------------------+

**[Assumptions Underlying Hypothesis Tests about Two Population
Variances]{.underline}**

All hypothesis tests use sampling distributions to determine the
probability of sample statistics. In order for us to be confident that
our choice of sampling distribution for any given test really is the way
the sample statistic is distributed, certain assumptions must be met. If
the assumptions are not met -- that is, if any given assumption is not
true -- then we cannot rely on the results of the hypothesis tests. They
may mislead us, give us the wrong answers, and cause us to draw the
wrong conclusions.

When making inferences about two population variances using $F$:

a)  The underlying populations must both be normally distributed. If
    they are not normal, then the sampling distribution is unknown, so
    you cannot use F as the sampling distribution.

b)  Both samples must be random, and they must be independent of one
    another. If they are not random and independent, then the sampling
    distribution is unknown, so you cannot use F as the sampling
    distribution.

## The Chi-Square Distribution {-}

The $\chi^{2}$ test statistics and $\chi^{2}$ sampling distributions are
used for inferences about a single population variance (Ch 11), goodness
of fit tests (Ch 12), and tests of independence (Ch 12).

The **Chi-Square distribution**:

-   is a probability distribution, so the area under the curve is 1

-   has degrees of freedom (df). The calculation for degrees of freedom
    will depend on the type of hypothesis test or confidence interval.

-   is ALWAYS positive and is NOT symmetrical

    -   Implication: Critical Values in the upper tail **and** lower
        tail will be **two different positive numbers**

-   The mean of a chi-square distribution is equal to its degrees of
    freedom. How is this relevant?

    -   If
        $\chi_{test}^{2}\mathbf{> df}$,
        then the test statistic is in the **upper tail**

    -   If
        $\chi_{test}^{2}\mathbf{< df}$,
        then the test statistic is in the **lower tail**

The Chi-Square table contains Critical Values. Use the column headings
marked "Area in Lower Tail" for LT critical values, and "Area in Upper
Tail" for UT critical values. Excel is used to calculate p-values for
Chi-Square test statistics.

The Hypothesis Testing rejection rules for $\chi^{2}$ test statistics
are listed in Ch 11: Handout \#2, Part 1.

### Exercise: Practice using Chi-Square {-}

***Exercise 1*:**

a\) If df = 20 and $\alpha = 0.10$, what is the critical value of
Chi-square for an upper tail test?

b\) Suppose the test-statistic in this upper tail test is
$\chi_{test}^{2} = 31.4$. Use the critical value approach to
decide whether or not to reject the null hypothesis.

c\) Suppose the test-statistic in this upper tail test is
$\chi_{test}^{2} = 31.4$. Use the p-value approach to decide
whether or not to reject the null hypothesis.

***Exercise 2:***

a\) If df = 45 and $\alpha = 0.05$, what is the critical value of
Chi-Square for a lower tail test?

b\) Suppose that the test-statistic in this lower tail test is
$\chi_{test}^{2} = 46.1$. Use the critical value approach to
decide whether or not to reject the null hypothesis.

c\) Suppose that the test-statistic in this lower tail test is
$\chi_{test}^{2} = 46.1$. Use the p-value approach to decide
whether or not to reject the null hypothesis.

***Exercise 3:***

a\) If df = 16 and $\alpha = 0.05$, what are the critical values of
Chi-square for a two tailed test?

b\) Suppose that the test-statistic in this two-tailed test is
$\chi_{test}^{2} = 27.88.$ Use the critical value approach to
decide whether or not to reject the null hypothesis.

c\) Suppose that the test-statistic in this two-tailed test is
$\chi_{test}^{2} = 27.88.$ Use the p-value approach to decide
whether or not to reject the null hypothesis.

## Exercise: Hypothesis Tests about a Single Population Variance {-}

*Example 1:* A cranberry juice manufacturing company has designed its
bottle filling process with a variance of 0.0225 ounces^2^. It conducts
regular quality control tests to see whether the process is running
according to this design specification. To that end, a quality control
analyst takes a random sample of 25 bottles of cranberry juice and finds
this sample has a variance of 0.04 ounces^2^. The population of bottle
contents is assumed to be normal.

Conduct and interpret a hypothesis test at the $\alpha = 0.05$
significance level to determine whether the population variance of the
contents of the bottles is different from 0.0225. Is there evidence that
the process is out of adjustment?

*\
*

*Example 2:* Kombucha is a sparkling, fermented tea which naturally
contains some alcohol. In order to prevent kombucha from being regulated
as an alcoholic beverage, makers must keep their tea from exceeding the
legal limit for alcohol percentage. In order to stay legal, the
manufacturer needs the population variance of their kombucha to be less
than 0.00985. The population is normally distributed. The manufacturer
takes a random sample of 66 bottles of kombucha and calculates a sample
variance of 0.00624.

Conduct and interpret a hypothesis test to determine whether the
population variance of alcohol percentage in the kombucha is less than
0.00985 at an $\alpha = 0.01$ significance level. Is the kombucha brewer
staying within the legal limit?

## The F distribution {-}

The F test statistic and F sampling distribution are used for inferences
about two population variances (Ch 11), analysis of variance tests (Ch
13), and regression analysis (Ch 14-15).

The $F$ distribution:

-   A probability distribution, so the area under the curve is 1

-   Has TWO separate degrees of freedom

    -   The *numerator degrees of freedom* $(df_{1})$*,* which is based
        on the numerator in the test statistic.

    -   The *denominator degrees of freedom* $(df_{2})$, which is based
        on the denominator of the test statistic.

-   is ALWAYS positive and is NOT symmetrical

    -   In hypothesis tests about two population variances, we will
        construct our test statistic to be in the upper tail, so there
        will be one critical value ${(F}_{\alpha})$ for the directional
        test (upper tail) and one critical value $(F_{\alpha/2})$ for
        the two-tailed test.

The F table contains a selection of Critical Values. Excel is used to
calculate p-values for F test statistics.

The Hypothesis Testing rejection rules for $F$ test statistics are
listed in Ch 11: Handout \#2, Part 2.

### Exercise: Practice using F {-}

*Exercise 1:* Consider an upper tail test at an $\alpha = .05$
significance level, with
$numerator\ degrees\ of\ freedom\ df = 25\ and\ denominator\ degrees\ of\ freedom\ df = 29.$

a)  What is the critical value?

b)  Suppose the test statistic is $F_{test} = 3.1$. By the
    > Critical Value approach, decide whether or not to reject the null
    > hypothesis.

c)  Suppose the test statistic is $F_{test} = 3.1$. By the
    > p-value approach, decide whether or not to reject the null
    > hypothesis.

*Exercise 2:* Consider a two-tailed test at an $\alpha = .05$
significance level, with
$numerator\ degrees\ of\ freedom\ df = 6\ and\ denominator\ degrees\ of\ freedom\ df = 7.$

a)  What is the critical value?

b)  Suppose that the test statistic is $F_{test} = 4.82$. By the
    Critical Value approach, decide whether or not to reject the null
    hypothesis.

c)  Suppose that the test statistic is $F_{test} = 4.82.$ By the
    p-value approach, decide whether or not to reject the null
    hypothesis.

## Exercise: Hypothesis Tests about Two Population Variances {-}

*Example 1:* Our transport company would like to prove that we have
lower variability in delivery times than our competitor. An analyst at
our company obtains two random, independent samples. A random sample of
41 of our deliveries had a variance in delivery time of 2.56. A random
sample of 61 of our competitor's deliveries had a variance in delivery
time of 4.15. Delivery times for both companies are normally
distributed.

Conduct and interpret a hypothesis test to determine whether we have a
lower population variance than our competitor at an $\alpha = 0.01$
significance level.

*Example 2:* A manufacturer of bathroom scales makes two models, Model A
and Model B. Reliability, which is the extent to which a measurement is
consistent (i.e. the same) when repeated under similar conditions, is an
important characteristic of a bathroom scale. A scale that is more
reliable can command a higher price. (HINT: Consider what reliability
means in terms of the variance)

The manufacturer conducted a series of tests in which it weighed a
standard 150lb weight on the two scales. It then sampled the weights
displayed on the scales. These were independent, random samples, and the
populations are assumed to be normally distributed. The sample size for
Model A was 21 weigh-ins and the sample variance was 0.16. The sample
size for Model B was 26 weigh-ins and the sample variance was 0.0625.

Conduct and interpret a hypothesis test to determine whether the
population variances for these two scales differ at the $\alpha = .05$
significance level. Based on your analysis, which scale should have a
higher price?
