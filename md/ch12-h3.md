**[Test of Independence for Two Categorical Variables]{.underline}**

Tests of Independence show whether or not there is a relationship
between two categorical variables measured on the same population.

> If two categorical variables are:
>
> • **[independent]{.underline}** of one another, the two variables are
> **[not related]{.underline}**
>
> • **[not independent]{.underline}** of one another, the two variables
> are **[related]{.underline}** (i.e. dependent)

1.  **[Formulating the Hypotheses]{.underline}**:

> The default assumption, which forms the null hypothesis in this type
> of test, is that the two variables are independent of one another. If
> you can reject the null hypothesis, that means the two variables are
> related.
>
> There is only one set of hypotheses for tests of independence. The two
> categorical variables are \[*Variable 1*\] and \[*Variable 2*\], and
> you should fill in what those variables are in the context of the
> problem when doing a test of independence. It doesn't matter which one
> is which, but you must maintain consistency in labeling throughout the
> problem.

+----------------------------------------------------------------------+
| **Hypotheses for Tests of Independence**                             |
+======================================================================+
| $H_{0}:\left\lbrack Variable\ 1 \right\rbrack\                       |
| text{\ is\ independent\ of\ }\left\lbrack Variable\ 2 \right\rbrack$ |
|                                                                      |
| $H_{A}:\left\lbrack Variable\ 1 \right\rbrack\text{                  |
| \ is\ not\ independent\ of\ }\left\lbrack Variable\ 2 \right\rbrack$ |
+----------------------------------------------------------------------+
| **Answers questions about:**                                         |
+----------------------------------------------------------------------+
| Whether or not \[*Variable 1*\] is related to \[*Variable 2*\]       |
+----------------------------------------------------------------------+
| NOTE:                                                                |
|                                                                      |
| 1.  \[*Variable 1*\] and \[*Variable 2*\] must both be categorical   |
|     variables                                                        |
+----------------------------------------------------------------------+

2.  **[The Test Statistic]{.underline}:**

> The logic is the similar to a Goodness of Fit test. The expected
> frequencies are the counts we expect to get for each joint category in
> the sample if the two variables are independent (that is, if the null
> hypothesis is true). Observed frequencies are the actual frequencies
> in the random sample. Some variation between observed and expected
> frequencies will occur due to random chance, so we use our hypothesis
> testing techniques and set a threshold (the
> $\text{α\ significance\ level}$) at which we consider the differences
> between observed and expected counts to be large enough to contradict
> the null hypothesis. If the differences between the expected and
> observed frequencies are large, then the sample contradicts the null
> hypothesis and it is rejected, with the conclusion that $H_{A}$ is
> true: the variables are not independent.
>
> The size of the difference between the observed and expected
> frequencies is quantified in our $\chi^{2}\ $test statistic, which is
> calculated according to this formula:

$$\chi_{\text{test}}^{2} = \sum_{i}^{}{\sum_{j}^{}\frac{\left( f_{\text{ij}} - e_{\text{ij}} \right)^{2}}{e_{\text{ij}}}}$$

where

$${f_{\text{ij}} = the\ observed\ frequencies\ from\ the\ sample
}{e_{\text{ij}} = the\ expected\ frequencies\ if\ the\ variables\ are\ independent}$$

$$\text{and}$$

$$the\ degrees\ of\ freedom\ are\ df = \left( r - 1 \right)\left( c - 1 \right)$$

> where

$$r = the\ number\ of\ categories\ in\ Variable\ 1$$

$$c = the\ number\ of\ categories\ in\ Variable\ 2$$

> We will use a contingency table with $i$ rows and $\text{j\ }$columns
> to begin our calculation of this test statistic.

3.  **[Deciding whether or not to Reject]{.underline}**
    $\mathbf{H}_{\mathbf{0}}$**:**

> Only large differences between the observed and expected frequencies
> constitute evidence against the null hypothesis, so all Tests of
> Independence are **[upper tail tests]{.underline}.**
>
> The two possible decisions are:

1.  $\text{Reject\ }H_{0}\text{\ and\ accept\ }H_{A}$

2.  $\text{Do\ not\ reject\ }H_{0}\text{\ and\ conclude\ that\ }H_{A}\text{\ is\ unsupported.}$

> REMINDER: you can never *accept* the null hypothesis. Remember the
> swans.

+----------------------------------+----------------------------------+
| **When to Reject**               |                                  |
| $\mathbf                         |                                  |
| {H}_{\mathbf{0}}\mathbf{\ }$**in |                                  |
| Tests of Independence:**         |                                  |
+==================================+==================================+
|                                  | **Always an Upper Tail Test:**   |
+----------------------------------+----------------------------------+
| **p-value approach:**            | Calculate the upper tail         |
|                                  | $p\text{-}\text{value}$ of       |
|                                  | $\chi_{\text{test}}^{2}$         |
|                                  |                                  |
|                                  | If the                           |
|                                  | $p\text{-}value \leq \ \alpha,$  |
|                                  | then reject $H_{0}$ and accept   |
|                                  | $H_{A}.$                         |
|                                  |                                  |
|                                  | If the                           |
|                                  | $p\text{-}value > \alpha$, then  |
|                                  | do not reject $H_{0}$. $H_{A}$   |
|                                  | is unsupported.                  |
+----------------------------------+----------------------------------+
| **Critical Value: Approach**     | Look up the UT Critical Value of |
|                                  | $\chi^{2}$, which is             |
|                                  | $\chi_{\alpha,UT}^{2}$           |
|                                  |                                  |
|                                  | If                               |
|                                  | $\chi_{\text{test}}^{2} \        |
|                                  | geq \chi_{\alpha,UT}^{2},\ $then |
|                                  | reject $H_{0}$and accept         |
|                                  | $H_{A}$.                         |
|                                  |                                  |
|                                  | If                               |
|                                  | $\chi_{\text{tes                 |
|                                  | t}}^{2} < \chi_{\alpha,UT}^{2}$, |
|                                  | then do not reject               |
|                                  | $H_{0}\text{.\ }H_{A}$ is        |
|                                  | unsupported.                     |
+----------------------------------+----------------------------------+
| NOTES:                           |                                  |
|                                  |                                  |
| 1)  $\chi_{\text{test}}^{2}\ $is |                                  |
|     a Test Statistic             |                                  |
|                                  |                                  |
| 2)  $\chi_{\alpha,UT}^{2}$ is a  |                                  |
|     Critical Value               |                                  |
|                                  |                                  |
| 3)  $\chi^{2}$ is based on       |                                  |
|     degrees of freedom. The      |                                  |
|     degrees of freedom in Tests  |                                  |
|     of Independence is           |                                  |
|                                  |                                  |
| $$d                              |                                  |
| f = \left( r - 1 \right)\left( c |                                  |
|  - 1 \right)\text{\ where\ r\ is |                                  |
| \ the\ number\ of\ categories}$$ |                                  |
|                                  |                                  |
| $$in\ Variable                   |                                  |
| \ 1\ and\ c\ is\ the\ number\ of |                                  |
| \ categories\ in\ Variable\ 2.$$ |                                  |
+----------------------------------+----------------------------------+

4.  **[Interpreting the test]{.underline}:**

> (Note: This explanation of interpretation holds for ALL hypothesis
> tests.) We start every hypothesis test with a question about the
> parameter of interest, so we must end every hypothesis test with the
> answer to that question. In other words, we must *interpret* the
> conclusion of our test in terms of the original question.
>
> Remember: in hypothesis testing you can never prove the null
> hypothesis. You can only prove the alternative hypothesis: when you
> reject the null and accept the alternative, then at your given
> $\alpha$ level of significance you may conclude that $H_{A}$ is true.
> If you do not reject $H_{0},\ $then you must conclude that $H_{A}$ is
> unsupported by the evidence. This gives us a clear guideline for how
> to *interpret* hypothesis tests: ***always look to the alternative
> hypothesis!***
>
> In all that follows, you would substitute the actual words and numbers
> from your hypothesis test for the symbols. Notice that each
> interpretation simply states the alternative hypothesis in words, and
> says either that it is true or that it is unsupported by the evidence.

+----------------------------------+----------------------------------+
| **How to Interpret a Test of     |                                  |
| Independence:**                  |                                  |
+==================================+==================================+
| **When you:**                    | **Interpretation:**              |
+----------------------------------+----------------------------------+
| **Reject**                       | At the $\text{α\ }$significance  |
| $\mathbf{H}_{\mathbf{0}}$        | level, we can conclude that      |
|                                  | \[*Variable 1*\] is not          |
|                                  | independent of \[*Variable 2*\]. |
|                                  | \[*Variable 1*\] and \[*Variable |
|                                  | 2*\] are related.                |
+----------------------------------+----------------------------------+
| **Do not reject**                | At the $\text{α\ }$significance  |
| $\mathbf{H}_{\mathbf{0}}$        | level, we cannot conclude that   |
|                                  | \[*Variable 1*\] and \[*Variable |
|                                  | 2*\] are related.                |
+----------------------------------+----------------------------------+
| NOTES:                           |                                  |
|                                  |                                  |
| 1)  When $H_{0}\ $is rejected,   |                                  |
|     you can:                     |                                  |
|                                  |                                  |
|     a.  look at the distribution |                                  |
|         of outcomes in the       |                                  |
|         sample for information   |                                  |
|         about the relationship   |                                  |
|         between \[*Variable 1*\] |                                  |
|         and \[*Variable 2*\].    |                                  |
|                                  |                                  |
|     b.  compare the expected     |                                  |
|         frequencies to the       |                                  |
|         observed frequencies to  |                                  |
|         learn about how the two  |                                  |
|         variables are related.   |                                  |
+----------------------------------+----------------------------------+

**[Assumptions Underlying These Hypothesis Tests]{.underline}**

All hypothesis tests use sampling distributions to determine the
probability of sample statistics. In order for us to be confident that
our choice of sampling distribution for any given test really is the way
the sample statistic is distributed, certain assumptions must be met. If
the assumptions are not met -- that is, if any given assumption is not
true -- then we cannot rely on the results of the hypothesis tests. They
may mislead us, give us the wrong answers, and cause us to draw the
wrong conclusions.

For Tests of Independence, the only assumption that must be satisfied is
that the expected frequency for each combination of categories must be
greater than five:

$$e_{\text{ij}} \geq 5$$

*Exercise.* An analyst for a chain of coffee shops suspects that a
customer's drink choice is related to the time of day when the customer
comes in. The three drink choices the analyst would like to consider are
Hot Coffee, Iced Coffee, and Specialty Drinks. The analyst takes a
random sample of 503 customers and then splits the customers into two
groups: those who came in before 11am and those who came in after 11am.
Of the customers who came in before 11am, 90 ordered Hot Coffee, 79
ordered Iced Coffee, and 72 ordered Specialty Drinks. Of the customers
who came in after 11am, 67 ordered Hot Coffee, 74 ordered Iced Coffee,
and 121 ordered Specialty Drinks.

Conduct a Test of Independence to find out whether drink choice is
related to time of visit at the α = .01 significance level.

[First]{.underline}, fill in the Observed Frequencies from the sample
data, then calculate the Row and Column Totals.

[Second]{.underline}, calculate the expected frequency, $e_{\text{ij}}$,
for each combination of categories:

$$e_{\text{ij}} = \ \frac{(Row\ i\ Total)(Column\ j\ Total)}{n}$$

where *i* is the row number, *j* is the column number, and n is the
sample size.

+-------------------------------------+-------------+------------+---------------+
| **Contingency Table:**              |             |            |               |
|                                     |             |            |               |
| $$\mathbf{f}_{\mathbf{\text{ij}}}$$ |             |            |               |
+=====================================+=============+============+===============+
|                                     | Before 11am | After 11am | **Row Total** |
+-------------------------------------+-------------+------------+---------------+
| Hot Coffee                          |             |            |               |
+-------------------------------------+-------------+------------+---------------+
| Iced Coffee                         |             |            |               |
+-------------------------------------+-------------+------------+---------------+
| Specialty Drink                     |             |            |               |
+-------------------------------------+-------------+------------+---------------+
| **Column Total**                    |             |            |               |
+-------------------------------------+-------------+------------+---------------+

NOTE: there are three categories of Drink Choice, so r = 3. There are
two categories of Time of Day, so c = 2. You will need this information
later to calculate degrees of freedom for the $\chi^{2}$ test statistic
and critical value.

[Third]{.underline}, fill in the following table. The sum of the last
column is the $\chi_{\text{test}}^{2}$ test statistic:

                  **Drink Choice**                                                                                                                                                                  **Time of Visit**   **Observed Frequency**   **Expected Frequency**   **Difference Squared/Expected Frequency**
  --------------- --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ------------------- ------------------------ ------------------------ ---------------------------------------------------------------------
  $$\text{ij}$$                                                                                                                                                                                                         $$f_{\text{ij}}$$        $$e_{\text{ij}}$$        $$\frac{{{(f}_{\text{ij}} - \ e_{\text{ij}})}^{2}}{e_{\text{ij}}}$$
  11              Hot Coffee                                                                                                                                                                        Before 11am                                                           
  12              Hot Coffee                                                                                                                                                                        After 11am                                                            
  21              Iced Coffee                                                                                                                                                                       Before 11am                                                           
  22              Iced Coffee                                                                                                                                                                       After 11am                                                            
  31              Specialty Drinks                                                                                                                                                                  Before 11am                                                           
  32              Specialty Drinks                                                                                                                                                                  After 11am                                                            
                  $$\chi_{\text{test}}^{2} = \sum_{i}^{}{\sum_{j}^{}\frac{{{(f}_{\text{ij}} - \ e_{\text{ij}})}^{2}}{e_{\text{ij}}}} = \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $$                                                                         

The $\chi^{2}$ test statistic and critical value for a test of
independence has (r -- 1)(c -- 1) degrees of freedom (see note from
previous page). Now you are ready to complete your hypothesis test.

[\[CHART\]]{.chart}
