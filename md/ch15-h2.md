**[Hypothesis Testing for Significance in Multiple
Regression]{.underline}**

The **Regression Model**,
$\mathbf{y =}\mathbf{\beta}_{\mathbf{0}}\mathbf{+}\mathbf{\beta}_{\mathbf{1}}\mathbf{x}_{\mathbf{1}}\mathbf{+ \ }\mathbf{\beta}_{\mathbf{2}}\mathbf{x}_{\mathbf{2}}\mathbf{+ \ldots +}\mathbf{\beta}_{\mathbf{p}}\mathbf{x}_{\mathbf{p}}\mathbf{+ \epsilon}$,
gives the relationship between $\text{y\ }$and the $x's$ in the
[population]{.underline}. From the sample, regression calculates the
**Estimated Regression Equation (ERE)**,
$\widehat{\mathbf{y}}\mathbf{=}\mathbf{b}_{\mathbf{0}}\mathbf{+}\mathbf{b}_{\mathbf{1}}\mathbf{x}_{\mathbf{1}}\mathbf{+}\mathbf{b}_{\mathbf{2}}\mathbf{x}_{\mathbf{2}}\mathbf{+ \ldots +}\mathbf{b}_{\mathbf{p}}\mathbf{x}_{\mathbf{p}}$,
which gives the relationship between $\text{y\ }$and the $x^{'}s$ in the
[sample]{.underline}.

**[Hypothesis Tests About the Population Slopes]{.underline}**

Each population slope gives the relationship between its corresponding
$x$ and $y$. The following table summarizes the possible relationships
between $\text{x\ }$and $y:$

  **Slope Coefficient**   **Relationship between** $\mathbf{\text{x\ }}$**and** $\mathbf{y}$
  ----------------------- --------------------------------------------------------------------
  $$If\ \beta > 0$$       Positive linear relationship
  $$If\ \beta < 0$$       Negative linear relationship
  $$If\ \beta = 0$$       No relationship

In order to conclude that there [is]{.underline} a relationship between
a given $\text{x\ }$and $y,$ we need to confirm that the population
slope coefficient on that $x$ does not equal zero. In **Chapter 14:
Handout \#2**, we learned that we can use a two-tailed $t$ test to
confirm whether the population slope is different from zero. In multiple
regression, we use that same procedure on *each* slope coefficient in
turn.

So, to confirm whether there is a relationship between $x_{1}$ and $y$,
the hypotheses would be:

$$H_{0}:\ \beta_{1} = 0$$

$$H_{A}:\ \beta_{1} \neq 0$$

If $H_{0}$ is rejected and $H_{A}$ is accepted, then there is a
relationship between $x_{1}$ and $\text{y.}$ In other words, the
relationship between $x_{1}$ and $y$ is statistically significant.

Then, to confirm whether there is a relationship between $x_{2}$ and
$y$, the hypotheses would be:

$$H_{0}:\ \beta_{2} = 0$$

$$H_{A}:\ \beta_{2} \neq 0$$

If $H_{0}$ is rejected and $H_{A}$ is accepted, then there is a
relationship between $x_{2}$ and $\text{y.}$ In other words, the
relationship between $x_{2}$ and $y$ is statistically significant.

.

.

.

Finally, to confirm whether there is a relationship between $x_{p}$ and
$y$, the hypotheses would be:

$$H_{0}:\ \beta_{p} = 0$$

$$H_{A}:\ \beta_{p} \neq 0$$

If $H_{0}$ is rejected and $H_{A}$ is accepted, then there is a
relationship between $x_{p}$ and $\text{y.}$ In other words, the
relationship between $x_{p}$ and $y$ is statistically significant.

Each slope coefficient must be tested separately. Luckily for us, Excel
calculates the $t_{\text{test}}$ test statistic and two-tailed p-value
for each slope coefficient and reports them in the regression output. We
just need to compare the p-value to $\alpha$ in each case. If the
p-value $\leq \ \alpha$, then we reject $H_{0}$ and conclude there is a
statistically significant relationship between the particular $x$ and
$y$.

Remember: when the null hypothesis is rejected in these hypothesis
tests, the conclusion is that the relationship between the given $x$ and
$y$ is *statistically significant*.

**[Hypothesis Test for the Overall Significance of the Regression
Model]{.underline}**

The $F$ test reported in the ANOVA table in the regression output tests
the overall significance of the regression model. It tests whether the
model *considered as a whole* is significant. Whereas the $t$ tests
discussed above test for the significance of the relationship between
each individual $x$ and $y$ separately, the $F$ test shows whether $y$
is related to the $\text{set\ of\ all\ }x^{'}s$, considered together.

Technically speaking, the $F$ test compares two different models for
predicting $y:$ the regression model, and the model in which the mean is
used to predict $y$ (called the intercept-only model). If you can reject
the null hypothesis in the $F$ test, then you know that using the
regression to predict $y$ at each $x$ is an improvement over using the
mean of $y$ to predict $y$ at each $x$, and that the improvement is
statistically significant.

1)  **[Formulating the Hypotheses]{.underline}:**

> There is only one form of hypotheses, but the number of $\beta's$ in
> it depends on how many IVs you have in your regression model.

+----------------------------------------------------------------------+
| **Hypotheses about the Overall Significance of the Regression        |
| Model**                                                              |
+======================================================================+
|                                                                      |
+----------------------------------------------------------------------+
| $$H_{0}:\ \beta_{1} = \beta_{2} = \ldots = \beta_{p} = 0$$           |
|                                                                      |
| $$H_{A}:\ One\ or\ more\ of\ the\ \beta^{'}\text{s\ is\ not\ zero}$$ |
+----------------------------------------------------------------------+
| Answers the question:                                                |
+----------------------------------------------------------------------+
| Whether the population slope coefficients are jointly different from |
| zero.                                                                |
|                                                                      |
| That is to say, whether the regression model considered as a whole   |
| is statistically significant.                                        |
+----------------------------------------------------------------------+

2)  **[The Test Statistic]{.underline}:**

> The test statistic is:

$$F_{\text{test}} = \frac{\text{MSR}}{\text{MSE}}$$

$$\text{MSR} = the\ Mean\ Square\ due\ to\ Regression$$

> with (numerator) degrees of freedom $df_{1} = p$

$$\text{MSE} = the\ Mean\ Square\ Error$$

> with (denominator) degrees of freedom $df_{2} = n - p - 1$

$${\text{where\ n} = the\ number\ of\ observations
}{p = the\ number\ of\ independent\ variables}$$

3)  **[Deciding whether or not to Reject]{.underline}**
    $\mathbf{H}_{\mathbf{0}}$**:**

> ANOVAs are always one-tailed, upper tail tests.
>
> To calculate the p-value by Excel function, you would use
> =F.DIST.RT($F_{\text{test}},\ numerator\ df_{1},\ denominator\ df_{2})$

+----------------------------------+----------------------------------+
|                                  | **Always a One-Tailed, Upper     |
|                                  | Tail Test:**                     |
+==================================+==================================+
| **p-value approach:**            | The upper-tailed                 |
|                                  | $p\text{-}\text{value}$ is the   |
|                                  | upper tail probability of        |
|                                  | $F_{\text{test}}.$               |
|                                  |                                  |
|                                  | If the                           |
|                                  | $p\text{-}value \leq \ \alpha,$  |
|                                  | then reject $H_{0}$ and accept   |
|                                  | $H_{A}.$                         |
|                                  |                                  |
|                                  | If the                           |
|                                  | $p\text{-}value > \ \alpha,$     |
|                                  | then do not reject               |
|                                  | $H_{0}\text{.\ }H_{A}$is         |
|                                  | unsupported.                     |
|                                  |                                  |
|                                  | **NOTE: this**                   |
|                                  | $\mathbf{                        |
|                                  | p}\text{-}\mathbf{\text{value}}$ |
|                                  | **is reported by Excel in the    |
|                                  | Regression Output as             |
|                                  | *Significance F* in the ANOVA    |
|                                  | table!!**                        |
+----------------------------------+----------------------------------+
| **Critical Value Approach:**     | If                               |
|                                  | $F                               |
|                                  | _{\text{test}} \geq F_{\alpha}$, |
|                                  | then reject $H_{0}$and accept    |
|                                  | $H_{A}$.                         |
|                                  |                                  |
|                                  | If                               |
|                                  | $F_{\text{test}} < F_{\alpha}$,  |
|                                  | then do not reject               |
|                                  | $H_{0}\text{.\ }H_{A}$is         |
|                                  | unsupported.                     |
+----------------------------------+----------------------------------+
| NOTES:                           |                                  |
|                                  |                                  |
| 1)  $F_{\text{test}}\ $is the    |                                  |
|     Test Statistic               |                                  |
|                                  |                                  |
| 2)  $F_{\alpha}$ is an upper     |                                  |
|     tail Critical Value          |                                  |
|                                  |                                  |
| 3)  The numerator degrees of     |                                  |
|     freedom are $df = p$, and    |                                  |
|     the denominator degrees of   |                                  |
|     freedom are $df = n - p - 1$ |                                  |
+----------------------------------+----------------------------------+

4)  **[Interpreting the test]{.underline}:**

+----------------------------------+----------------------------------+
| **When you:**                    | **The Interpretation is:**       |
+==================================+==================================+
| **Reject**                       | At the $\alpha$ significance     |
| $\mathbf{H}_{\mathbf{0}}$        | level, we can conclude that      |
|                                  | overall regression model is      |
|                                  | statistically significant.       |
|                                  |                                  |
|                                  | A significant relationship is    |
|                                  | present between $y$ and          |
|                                  | $x_{1},x_                        |
|                                  | {2},\ldots,\ x_{p},\ $considered |
|                                  | together.                        |
|                                  |                                  |
|                                  | Our regression model will do a   |
|                                  | better job predicting            |
|                                  | $\text{y\ }$than using the mean  |
|                                  | to predict $\text{y.}$           |
+----------------------------------+----------------------------------+
| **Do not reject**                | At the $\alpha$ significance     |
| $\mathbf{H}_{\mathbf{0}}$        | level, we cannot conclude that   |
|                                  | the overall regression model is  |
|                                  | statistically significant.       |
+----------------------------------+----------------------------------+
