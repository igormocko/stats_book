<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Ch 13: Experimental Design and Analysis of Variance | Statistics Book</title>
  <meta name="description" content="Ch 13: Experimental Design and Analysis of Variance | Statistics Book" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Ch 13: Experimental Design and Analysis of Variance | Statistics Book" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Ch 13: Experimental Design and Analysis of Variance | Statistics Book" />
  
  
  

<meta name="author" content="Catherine Schmitt-Sands" />


<meta name="date" content="2020-07-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch-12-tests-of-goodness-of-fit-and-independence.html"/>
<link rel="next" href="ch-14-simple-linear-regression.html"/>
<script src="libs/header-attrs-2.2/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!DOCTYPE html>
<!-- KaTeX requires the use of the HTML5 doctype. Without it, KaTeX may not render properly -->
<html>
  <head>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>

    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
  </head>
</html>



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">Stats Book</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#definitions-and-notation"><i class="fa fa-check"></i>Definitions and Notation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html"><i class="fa fa-check"></i>Hypothesis Tests</a>
<ul>
<li class="chapter" data-level="" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#the-z-distribution"><i class="fa fa-check"></i>The z Distribution</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#hypothesis-testing-the-process"><i class="fa fa-check"></i>Hypothesis Testing: The Process</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#hypothesis-tests-about-a-single-population-mean"><i class="fa fa-check"></i>Hypothesis Tests about a Single Population Mean</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#hypothesis-tests-about-a-single-population-proportion"><i class="fa fa-check"></i>Hypothesis Tests about a Single Population Proportion</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#the-t-distribution"><i class="fa fa-check"></i>The t Distribution</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#hypotheses-about-a-single-population-proportion"><i class="fa fa-check"></i>Hypotheses about a Single Population Proportion</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#type-i-and-type-ii-error"><i class="fa fa-check"></i>Type I and Type II Error</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-10-inference-about-means-and-proportions-with-two-populations.html"><a href="ch-10-inference-about-means-and-proportions-with-two-populations.html"><i class="fa fa-check"></i>Ch 10: Inference About Means and Proportions with Two Populations</a>
<ul>
<li class="chapter" data-level="" data-path="ch-10-inference-about-means-and-proportions-with-two-populations.html"><a href="ch-10-inference-about-means-and-proportions-with-two-populations.html#notation-definitions"><i class="fa fa-check"></i>Notation &amp; Definitions</a></li>
<li class="chapter" data-level="" data-path="ch-10-inference-about-means-and-proportions-with-two-populations.html"><a href="ch-10-inference-about-means-and-proportions-with-two-populations.html#hypothesis-tests-about-the-difference-between-population-means"><i class="fa fa-check"></i>Hypothesis Tests about the Difference between Population Means</a></li>
<li class="chapter" data-level="" data-path="ch-10-inference-about-means-and-proportions-with-two-populations.html"><a href="ch-10-inference-about-means-and-proportions-with-two-populations.html#hypothesis-tests-about-the-difference-between-two-population-proportions"><i class="fa fa-check"></i>Hypothesis Tests about the Difference between Two Population Proportions</a></li>
<li class="chapter" data-level="" data-path="ch-10-inference-about-means-and-proportions-with-two-populations.html"><a href="ch-10-inference-about-means-and-proportions-with-two-populations.html#confidence-intervals"><i class="fa fa-check"></i>Confidence Intervals</a></li>
<li class="chapter" data-level="" data-path="ch-10-inference-about-means-and-proportions-with-two-populations.html"><a href="ch-10-inference-about-means-and-proportions-with-two-populations.html#confidence-intervals-for-the-difference-between-two-population-means"><i class="fa fa-check"></i>Confidence Intervals for the Difference between Two Population Means</a></li>
<li class="chapter" data-level="" data-path="ch-10-inference-about-means-and-proportions-with-two-populations.html"><a href="ch-10-inference-about-means-and-proportions-with-two-populations.html#confidence-intervals-for-the-difference-between-two-proportions"><i class="fa fa-check"></i>Confidence Intervals for the Difference Between Two Proportions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-11-inferences-about-population-variances.html"><a href="ch-11-inferences-about-population-variances.html"><i class="fa fa-check"></i>Ch 11: Inferences About Population Variances</a>
<ul>
<li class="chapter" data-level="" data-path="ch-11-inferences-about-population-variances.html"><a href="ch-11-inferences-about-population-variances.html#notation-definitions-1"><i class="fa fa-check"></i>Notation &amp; Definitions</a></li>
<li class="chapter" data-level="" data-path="ch-11-inferences-about-population-variances.html"><a href="ch-11-inferences-about-population-variances.html#hypothesis-tests-about-a-single-population-variance"><i class="fa fa-check"></i>Hypothesis Tests about a Single Population Variance</a></li>
<li class="chapter" data-level="" data-path="ch-11-inferences-about-population-variances.html"><a href="ch-11-inferences-about-population-variances.html#hypothesis-tests-about-two-population-variances"><i class="fa fa-check"></i>Hypothesis Tests about Two Population Variances</a></li>
<li class="chapter" data-level="" data-path="ch-11-inferences-about-population-variances.html"><a href="ch-11-inferences-about-population-variances.html#the-chi-square-distribution"><i class="fa fa-check"></i>The Chi-Square Distribution</a></li>
<li class="chapter" data-level="" data-path="ch-11-inferences-about-population-variances.html"><a href="ch-11-inferences-about-population-variances.html#the-f-distribution"><i class="fa fa-check"></i>The F distribution</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-12-tests-of-goodness-of-fit-and-independence.html"><a href="ch-12-tests-of-goodness-of-fit-and-independence.html"><i class="fa fa-check"></i>Ch 12: Tests of Goodness of Fit and Independence</a>
<ul>
<li class="chapter" data-level="" data-path="ch-12-tests-of-goodness-of-fit-and-independence.html"><a href="ch-12-tests-of-goodness-of-fit-and-independence.html#multinomial-probability-distributions"><i class="fa fa-check"></i>Multinomial Probability Distributions</a></li>
<li class="chapter" data-level="" data-path="ch-12-tests-of-goodness-of-fit-and-independence.html"><a href="ch-12-tests-of-goodness-of-fit-and-independence.html#goodness-of-fit-test-for-a-single-categorical-variable"><i class="fa fa-check"></i>Goodness-of-Fit Test for a Single Categorical Variable</a></li>
<li class="chapter" data-level="" data-path="ch-12-tests-of-goodness-of-fit-and-independence.html"><a href="ch-12-tests-of-goodness-of-fit-and-independence.html#test-of-independence-for-two-categorical-variables"><i class="fa fa-check"></i>Test of Independence for Two Categorical Variables</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-13-experimental-design-and-analysis-of-variance.html"><a href="ch-13-experimental-design-and-analysis-of-variance.html"><i class="fa fa-check"></i>Ch 13: Experimental Design and Analysis of Variance</a>
<ul>
<li class="chapter" data-level="" data-path="ch-13-experimental-design-and-analysis-of-variance.html"><a href="ch-13-experimental-design-and-analysis-of-variance.html#experimental-design"><i class="fa fa-check"></i>Experimental Design</a></li>
<li class="chapter" data-level="" data-path="ch-13-experimental-design-and-analysis-of-variance.html"><a href="ch-13-experimental-design-and-analysis-of-variance.html#introduction-to-analysis-of-variance-anova"><i class="fa fa-check"></i>Introduction to Analysis of Variance (ANOVA)</a></li>
<li class="chapter" data-level="" data-path="ch-13-experimental-design-and-analysis-of-variance.html"><a href="ch-13-experimental-design-and-analysis-of-variance.html#calculating-the-anova-test-statistic-and-summary-table"><i class="fa fa-check"></i>Calculating the ANOVA Test Statistic and Summary Table</a></li>
<li class="chapter" data-level="" data-path="ch-13-experimental-design-and-analysis-of-variance.html"><a href="ch-13-experimental-design-and-analysis-of-variance.html#fishers-least-significant-difference-a-multiple-comparison-procedure"><i class="fa fa-check"></i>Fisher’s Least Significant Difference: a Multiple Comparison Procedure</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-14-simple-linear-regression.html"><a href="ch-14-simple-linear-regression.html"><i class="fa fa-check"></i>Ch 14: Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="" data-path="ch-14-simple-linear-regression.html"><a href="ch-14-simple-linear-regression.html#introduction-1"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="ch-14-simple-linear-regression.html"><a href="ch-14-simple-linear-regression.html#hypothesis-testing-in-simple-linear-regression"><i class="fa fa-check"></i>Hypothesis Testing in Simple Linear Regression</a></li>
<li class="chapter" data-level="" data-path="ch-14-simple-linear-regression.html"><a href="ch-14-simple-linear-regression.html#simple-linear-regression-what-it-all-means"><i class="fa fa-check"></i>Simple Linear Regression: What it all means</a></li>
<li class="chapter" data-level="" data-path="ch-14-simple-linear-regression.html"><a href="ch-14-simple-linear-regression.html#simple-linear-regression-an-example"><i class="fa fa-check"></i>Simple Linear Regression: An Example</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-15-multiple-regression.html"><a href="ch-15-multiple-regression.html"><i class="fa fa-check"></i>Ch 15: Multiple Regression</a>
<ul>
<li class="chapter" data-level="" data-path="ch-15-multiple-regression.html"><a href="ch-15-multiple-regression.html#multiple-regression"><i class="fa fa-check"></i>Multiple Regression</a></li>
<li class="chapter" data-level="" data-path="ch-15-multiple-regression.html"><a href="ch-15-multiple-regression.html#hypothesis-testing-for-significance-in-multiple-regression"><i class="fa fa-check"></i>Hypothesis Testing for Significance in Multiple Regression</a></li>
<li class="chapter" data-level="" data-path="ch-15-multiple-regression.html"><a href="ch-15-multiple-regression.html#how-to-handle-insignificant-xs"><i class="fa fa-check"></i>How to handle insignificant x’s</a></li>
<li class="chapter" data-level="" data-path="ch-15-multiple-regression.html"><a href="ch-15-multiple-regression.html#model-comparisons"><i class="fa fa-check"></i>Model Comparisons</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-13-experimental-design-and-analysis-of-variance" class="section level1 unnumbered" number="">
<h1>Ch 13: Experimental Design and Analysis of Variance</h1>
<div class="hero-image-container">
<p><img class= "hero-image" src="../artwork/05.png"></p>
</div>
<div id="experimental-design" class="section level2 unnumbered" number="">
<h2>Experimental Design</h2>
<p>An <em>experimental design</em> is a plan and a process for gathering data in
which the researcher controls, modifies, or manipulates at least one
variable. The purpose of gathering data in any research design,
including experimental design, is to test hypotheses.</p>
<p>In a study with an experimental design, the researcher begins with an
idea about cause and effect. The researcher wants to test whether a
treatment causes a response. To do this, each treatment is applied to a
different group, and the mean responses of the groups are measured and
compared to each other.</p>
<p><span class="underline">Terminology:</span></p>
<ul>
<li><p>A <span class="underline">factor</span> is an explanatory variable, also called an
Independent Variable (IV). It is the variable that the researcher
controls, modifies, or manipulates to see what happens.</p>
<ul>
<li>The <span class="underline">treatments</span> are different levels or categories
of the factor.</li>
</ul></li>
<li><p><span class="underline">Experimental units</span> are the objects or subjects whose
response the researcher is measuring. Experimental units are
assigned to <span class="underline">treatment groups</span> which are groups of
experimental units receiving a particular treatment.</p></li>
<li><p>A <span class="underline">response variable</span> is the Dependent Variable (DV). It
is what the researcher expects to vary with different treatments.</p>
<ul>
<li>A <span class="underline">response</span> is a single measurement of the response
variable for a given experimental unit.</li>
</ul></li>
<li><p><span class="underline">Random assignment</span> is the process of randomly assigning
experimental units to treatment groups, or randomly assigning
treatments to experimental units. <strong>Random assignment makes the
groups equivalent at the outset of the study…. so any changes you
see in the groups after applying the treatments, can be attributed
to the treatments themselves.</strong></p></li>
</ul>
<p>Two types of experimental design:</p>
<ol style="list-style-type: decimal">
<li><p><span class="underline">Fully randomized experimental design</span>: The treatments
are randomly assigned to the groups, or, equivalently, the groups
are randomly assigned to the treatments. In either case, the
treatments are randomly assigned <span class="underline">by the researcher</span>.
This is the key component of a fully randomized experimental design.
The researcher imposes changes or otherwise manipulates the
treatments that the groups receive.</p>
<ol style="list-style-type: lower-alpha">
<li><p><strong><span class="underline">Can</span> prove cause and effect.</strong> This is because
the process of randomly assigning treatment groups makes the
groups equivalent at the outset. Everything other than the
treatment that could affect the response is randomly distributed
among the groups. Therefore, any difference in the mean response
between treatment groups must be due to the treatment itself.</p>
<ol style="list-style-type: lower-roman">
<li>In a fully randomized experimental design, it is appropriate
to call the Independent Variable (the factor) the <em>cause</em>
and the Dependent Variable (the response) the <em>effect.</em> This
is because you can prove cause and effect with a fully
randomized experiment.</li>
</ol></li>
</ol></li>
<li><p><span class="underline">Nonrandomized experimental design</span>: also called
quasi-experimental design. The treatments are not randomly assigned
by the researcher, but different groups still receive different
treatments.</p>
<ol style="list-style-type: lower-alpha">
<li><strong><span class="underline">Cannot</span> prove cause and effect.</strong></li>
</ol></li>
</ol>
<p>Both experimental designs contrast with another type of study design:
<span class="underline">observational design</span>. In observational designs, outcomes
are observed and measured for different groups, but there is no
assignment of treatments to different groups. Researchers using
observational designs look at ongoing behavior – they <span class="underline">do not impose
any changes</span> in any variables. These studies are useful to
illuminate associations and relationships between variables but <strong>they
cannot prove cause and effect</strong>. In order for observational studies to
have validity, they must use random sampling from the population of
interest.</p>
<p>In both nonrandomized experimental design and observational design,
there is no way to completely rule out the possibility that there are
pre-existing differences between treatment groups that explain differing
responses. This is why these types of studies do not prove cause and
effect.</p>
<div id="excercise-xperimental-design-exercise" class="section level3 unnumbered" number="">
<h3>Excercise: xperimental Design: Exercise</h3>
<p>A local grocery store would like to increase sales on produce. This
grocery store tracks purchases at the customer level.</p>
<p>The grocery store decided that an effective way to boost sales of
produce might be to redesign the weekly ad that customers receive. In
the current design (Weekly Ad A), produce is on an inside page, the
pictures are small, and the emphasis is on price. In the second design
(Weekly Ad B), the produce is featured on the front page, beautifully
photographed in full color, and there are recipes that incorporate
produce. In the third design (Weekly Ad C) is the same as Design B
except that there are no recipes.</p>
<p>The grocery store takes a random sample of customers. These customers
are randomly assigned to receive one of the three Weekly Ad designs. The
customers’ purchases are tracked and their weekly spending on produce is
measured.</p>
<p>1) What is the <strong>factor</strong> in this experiment?</p>
<p>2) What are two other terms for <strong>factor</strong>?</p>
<p>3) What are the <strong>treatments</strong>? How many treatments are there?</p>
<p>4) How many groups of customers will there be in this experiment?</p>
<p>5) What is the <strong>response variable</strong> in this experiment?</p>
<p>6) What is another term for <strong>response variable</strong>?</p>
<p>7) What are the <strong>experimental units</strong>?</p>
<p>8) Give an example of a <strong>response</strong> in this study.</p>
<p>9) Is this a fully randomized experiment? How do you know?</p>
<p>10) Suppose that differences in Weekly Spending on Produce are observed
among the groups after they receive the Ads. Can the researcher conclude
that the Weekly Ad Design <em>caused</em> those differences?</p>
</div>
</div>
<div id="introduction-to-analysis-of-variance-anova" class="section level2 unnumbered" number="">
<h2>Introduction to Analysis of Variance (ANOVA)</h2>
<p>ANOVA is a hypothesis testing procedure that allows us to test the
equality of three or more population means in one hypothesis test.</p>
<p>ANOVA is used to test whether the mean response differs between
treatment groups in fully randomized and quasi-experimental designs. It
is also used to test between-group differences in observational studies
when the samples are random.</p>
<ol style="list-style-type: decimal">
<li><strong><span class="underline">Formulating the Hypotheses:</span></strong></li>
</ol>
<blockquote>
<p>There is only one general form of hypotheses for ANOVA. It is adapted
to each particular ANOVA depending on how many groups there are in a
particular analysis.</p>
<p>NOTE: <span class="math inline">\(k = the\ number\ of\ groups\)</span></p>
</blockquote>
<table style="width:99%;">
<colgroup>
<col width="98%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Hypotheses for Analysis of Variance (ANOVA)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p><span class="math inline">\(H_{0}:\mu_{1} = \ \mu_{2} = \ldots = \ \mu_{k}\)</span></p>
<p><span class="math display">\[H_{A}:Not\ all\ of\ the\ means\ are\ equal\]</span></p></td>
</tr>
<tr class="even">
<td><strong>Answers questions about:</strong></td>
</tr>
<tr class="odd">
<td>Whether at least one group has a different mean than the others.</td>
</tr>
<tr class="even">
<td><p>NOTE:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\mu_{1} ,\mu_{2},\ldots,\mu_{k}\text{\ are\ the\ means\ of\ the\ dependent\
}\left( \text{response} \right)\text{\ variable\ for\ each\ group.}\)</span></p></li>
<li><p><span class="math inline">\(k = the\ number\ of\ groups\)</span></p></li>
<li><p>the alternative hypothesis may be stated as
<span class="math inline">\(H_{A}:At\ least\ two\ of\ the\ population\)</span></p></li>
</ol>
<blockquote>
<p><span class="math inline">\(\text{means\ are\ not\ equal}\)</span>. These two forms of <span class="math inline">\(H_{A}\)</span> are
equivalent to one another.</p>
</blockquote></td>
</tr>
</tbody>
</table>
<ol start="2" style="list-style-type: decimal">
<li><strong><span class="underline">The Test Statistic:</span></strong></li>
</ol>
<blockquote>
<p>In order to understand the test statistic, we need to know something
about the process behind ANOVA. ANOVA estimates the variance of the
dependent variable two different ways, and compares those variance
estimates using an F test statistic. The two variance estimates are:</p>
</blockquote>
<ol style="list-style-type: decimal">
<li><p>The between-treatments estimate of the variance, also called the
<strong>Mean Square due to Treatments (MSTR)</strong></p>
<ol style="list-style-type: lower-alpha">
<li>The MSTR is the variance estimated under the assumption that
<span class="math inline">\(H_{0}\ \)</span>is true</li>
</ol></li>
<li><p>The within-treatments estimate of the variance, also called the
<strong>Mean Square due to Error (MSE)</strong></p>
<ol style="list-style-type: lower-alpha">
<li>The MSE is the variance estimated under the assumption that
<span class="math inline">\(H_{0}\ \)</span>is false</li>
</ol></li>
</ol>
<blockquote>
<p>The test statistic in ANOVA procedures is <span class="math inline">\(F\)</span>, and it is the ratio of
the two variance estimates: the MSTR and the MSE. The by-hand
calculation of this test statistic is the subject of its own handout.
The equation is:</p>
</blockquote>
<p><span class="math display">\[F_{\text{test}} = \frac{\text{MSTR}}{\text{MSE}}\]</span></p>
<blockquote>
<p>with</p>
</blockquote>
<p><span class="math display">\[{numerator\ degrees\ of\ freedom = df_{1} = k - 1
}{denominator\ degrees\ of\ freedom = df_{2} = n_{T} - k}\]</span></p>
<blockquote>
<p>where</p>
</blockquote>
<p><span class="math display">\[{k = the\ number\ of\ groups
}{n_{T} = total\ sample\ size\ (of\ all\ the\ groups)}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><strong><span class="underline">Deciding whether or not to Reject</span></strong>
<span class="math inline">\(\mathbf{H}_{\mathbf{0}}\)</span><strong>:</strong></li>
</ol>
<blockquote>
<p>ANOVA <span class="math inline">\(F\)</span> tests are always <span class="underline"><strong>one-tailed, upper tail
tests</strong>.</span> The reason for this is due to the nature of the
two variance estimates: the MSTR and the MSE. Here is how ANOVA works.
If <span class="math inline">\(H_{0}\)</span> is actually true and all the means of the groups are equal,
then both the MSTR and the MSE will yield similar estimates of the
true variance. Therefore, the ratio of MSTR and MSE (which is
<span class="math inline">\(F)\ \)</span>will be a small number – too small to cause us to reject
<span class="math inline">\(H_{0}.\)</span> If, on the other hand, <span class="math inline">\(H_{0}\)</span> is actually false, and the
means of the groups are not all equal, the MSTR will vastly
overestimate the true variance, while the MSE will estimate the true
variance accurately. Therefore, the ratio of the MSTR and MSE (which
is <span class="math inline">\(F)\ \)</span>will be a large number – large enough to cause us to reject
<span class="math inline">\(H_{0}.\)</span> We only want to reject the null when the difference between
MSTR and MSE is large, hence the use of the upper tail test.</p>
</blockquote>
<table style="width:97%;">
<colgroup>
<col width="48%" />
<col width="48%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>When to Reject</strong>
<span class="math inline">\(\mathbf{H}_{\mathbf{0}}\)</span> <strong>in
ANOVA (the Test Statistic is</strong>
<span class="math inline">\(\mathbf {F}_{\mathbf{\text{test}}}\)</span><strong>)</strong></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td><strong>Always an Upper Tail Test:</strong></td>
</tr>
<tr class="even">
<td><strong>p-value approach:</strong></td>
<td><p>Calculate the upper tail
<span class="math inline">\(p\text{-}\text{value}\)</span> of
<span class="math inline">\(F_{\text{test}}.\)</span></p>
<p>If the
<span class="math inline">\(\text{UT\
 p}\text{-}value \leq \ \alpha,\)</span>
then reject <span class="math inline">\(H_{0}\)</span> and accept
<span class="math inline">\(H_{A}.\)</span></p>
<p>If the
<span class="math inline">\(\tex t{UT\ p}\text{-}value &gt; \alpha\)</span>,
then do not reject
<span class="math inline">\(H_{0}\text{.\ }H_{A}\)</span> is
unsupported.</p></td>
</tr>
<tr class="odd">
<td><strong>Critical Value Approach:</strong></td>
<td><p>If
<span class="math inline">\(F_{\tex t{test}} \geq F_{\alpha},\ \)</span>then
reject <span class="math inline">\(H_{0}\)</span> and accept
<span class="math inline">\(H_{A}.\)</span></p>
<p>If
<span class="math inline">\(F_{\text{test}} &lt; F_{\alpha}\)</span>,
then do not reject
<span class="math inline">\(H_{0}\text{.\ }H_{A}\)</span> is
unsupported.</p></td>
</tr>
<tr class="even">
<td><p>NOTES:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(F_{\text{test}}\ \)</span>is the
Test Statistic</p></li>
<li><p><span class="math inline">\(F_{\alpha}\)</span> is the upper
tail Critical Value (from
the <span class="math inline">\(F\)</span> table).</p></li>
<li><p>The
<span class="math inline">\(\text{numerator\
 degrees\ of\ freedom} = k - 1\)</span>,
<span class="math inline">\(\text{denominator\ de
grees\ of\ freedom} = n_{T} - k\)</span></p></li>
</ol>
<p>where</p>
<p><span class="math display">\[{k = the\ number\ of\ groups
}{n_{T} = total\ sample\
 size\ (of\ all\ the\ groups)}\]</span></p></td>
<td></td>
</tr>
</tbody>
</table>
<ol start="4" style="list-style-type: decimal">
<li><strong><span class="underline">Interpreting the test</span>:</strong></li>
</ol>
<table style="width:97%;">
<colgroup>
<col width="48%" />
<col width="48%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>How to Interpret an ANOVA:</strong></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>When you:</strong></td>
<td><strong>Interpretation:</strong></td>
</tr>
<tr class="even">
<td><strong>Reject</strong>
<span class="math inline">\(\mathbf{H}_{\mathbf{0}}\)</span></td>
<td>At the <span class="math inline">\(\text{α\ }\)</span>significance
level, we can conclude that not
all of the population means are
equal. <em>Could also be stated:</em>
At the <span class="math inline">\(\text{α\ }\)</span>significance
level, we can conclude that at
least one of the populations has
a different mean than the
others.</td>
</tr>
<tr class="odd">
<td><strong>Do not reject</strong>
<span class="math inline">\(\mathbf{H}_{\mathbf{0}}\)</span></td>
<td>At the <span class="math inline">\(\text{α\ }\)</span>significance
level, we cannot conclude that
any of the population means are
different from one another.</td>
</tr>
<tr class="even">
<td><p>NOTES:</p>
<ol style="list-style-type: decimal">
<li>When <span class="math inline">\(H_{0}\ \)</span>is rejected,
you can then perform
comparisons of pairs of
means from the ANOVA to
determine which one is
different (or which ones are
different)</li>
</ol></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong><span class="underline">Assumptions Underlying ANOVA Tests</span></strong></p>
<p>ANOVA relies on <span class="underline">three assumptions</span>:</p>
<ol style="list-style-type: decimal">
<li><p>For each population, the response variable (dependent variable) is
normally distributed.</p>
<ol style="list-style-type: lower-alpha">
<li>Each treatment group in an experiment represents a potentially
different population, and in each population, the response
variable, also called the dependent variable, must be normally
distributed. This holds true for groups in observational studies
as well.</li>
</ol></li>
<li><p>The variance of the response variable is the same for all of the
populations.</p></li>
<li><p>The observations must be independent.</p>
<ol style="list-style-type: lower-alpha">
<li><p>In experimental designs, this assumption is satisfied by the use
of <span class="underline">random assignment</span> to place experimental units
into treatment groups.</p></li>
<li><p>In observational designs, this assumption is satisfied by using
<span class="underline">random sampling</span>.</p></li>
</ol></li>
</ol>
</div>
<div id="calculating-the-anova-test-statistic-and-summary-table" class="section level2 unnumbered" number="">
<h2>Calculating the ANOVA Test Statistic and Summary Table</h2>
<p>We calculate the F test statistic from the sample data. In ANOVA, this
is no easy task. It involves a series</p>
<p>of new equations and careful attention to detail.</p>
<p>NOTE: A <em>balanced design</em> is one in which all the groups are the same
size (all have the same <span class="math inline">\(n\)</span>). An <em>unbalanced design</em> is one in which at
least one group is a different size than the others. The book and
MindTap use two different sets of equations for calculating the
<span class="math inline">\(F_{\text{test}}\)</span> in ANOVA, and one set <strong>only</strong> works if you have a
balanced design. <strong>The formulas in this handout will work properly no
matter which design is being used, so I recommend you just stick with
these.</strong></p>
<p><span class="underline">For the following equations</span>:</p>
<p>There are <span class="math inline">\(k\)</span> treatment groups. Each group has a sample size, called
<span class="math inline">\(n_{j}\)</span> for the jth treatment group (e.g. the second treatment group has
a sample size of <span class="math inline">\(n_{2}\)</span>). Keep this notation in mind.</p>
<p>The <span class="math inline">\(\mathbf{\text{F\ }}\)</span><strong>test statistic</strong> has a <strong>numerator</strong> and a
<strong>denominator</strong> that must be calculated separately.</p>
<ol style="list-style-type: decimal">
<li><p><strong><span class="underline">The numerator of the F test statistic is the MSTR:</span></strong></p>
<ul>
<li>Recall: the MSTR is the Mean Square due to Treatments, also
called the between-treatments estimate of the variance. This is
the estimate of the true variance under the assumption that
<span class="math inline">\(H_{0}\)</span> is true, which would mean that all the group population
means were equal.</li>
</ul></li>
</ol>
<blockquote>
<p>Here are the <strong>four</strong> steps to calculate the <span class="math inline">\(\mathbf{\text{MSTR}}\)</span>:</p>
</blockquote>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(First,\ calculate\ the\ total\ sample\ size,n_{T}\ :\)</span></li>
</ol>
<p><span class="math display">\[\text{\ \ }n_{T} = n_{1} + n_{2} + \ldots + n_{k}\]</span></p>
<blockquote>
<p>NOTE: The total sample size, <span class="math inline">\(n_{T}\ \)</span>is just the sum of the sample
sizes of each group</p>
</blockquote>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(Second,\ calculate\ the\ overall\ sample\ mean,\overset{̿}{\overline{x}}\ :\ \)</span></li>
</ol>
<p><span class="math display">\[\overset{̿}{\overline{x}} = \ \frac{n_{1}{\overline{x}}_{1} + \ n_{2}{\overline{x}}_{2} + \ldots + n_{k}{\overline{x}}_{k}}{n_{T}}\ \]</span></p>
<p><span class="math display">\[{\text{where\ }n_{1},\ n_{2},\ldots,n_{k} = sample\ size\ for\ each\ group\ 
}{{\overline{x}}_{1},\ {\overline{x}}_{2},\ldots,{\overline{x}}_{k} = the\ sample\ mean\ for\ each\ group}\]</span></p>
<blockquote>
<p>NOTE:
<span class="math inline">\(\overset{̿}{\overline{x}} = the\ overall\ sample\ mean,\ is\ also\ called\ the\ Grand\ Mean,\ or\ x\text{-}\text{triple}\text{-}\text{bar}\)</span></p>
<p>3)
<span class="math inline">\(Third,\ calculate\ the\ Sum\ of\ Squares\ due\ to\ Treatments,\ SSTR:\)</span></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td align="left"><span class="math display">\[SSTR = \ \sum_{j = 1}^{k}{n_{j}\ ({\overline{x}}_{j} - \ \overset{̿}{\overline{x}}})^{2}\]</span></td>
<td align="left">$${n_{j} = sample size for group j</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">}{{}_{j} = the sample mean for group j</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">}{k = the number of groups}$$</td>
</tr>
</tbody>
</table>
<blockquote>
<p>4) <span class="math inline">\(Finally,\ use\ the\ SSTR\ to\ calculate\ the\ MSTR:\)</span></p>
</blockquote>
<p><span class="math display">\[MSTR = \ \frac{\text{SSTR}}{k - 1}\]</span></p>
<p><span class="math display">\[\text{where\ k} = the\ number\ of\ groups
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><strong><span class="underline">The denominator of the</span></strong> <span class="math inline">\(\mathbf{F}\)</span> <strong><span class="underline">test
statistic is the</span></strong>
<span class="math inline">\(\mathbf{\text{MSE}}\)</span><strong><span class="underline">:</span></strong></li>
</ol>
<ul>
<li>The MSE is the Mean Square due to Error, also called the
within-treatments estimate of the variance. This is the estimate of
the true variance under the assumption that <span class="math inline">\(H_{0}\)</span> is false, which
would mean that at least one group population mean was different
than the others.</li>
</ul>
<blockquote>
<p>Here are the <strong>two</strong> steps to calculate the <span class="math inline">\(\mathbf{\text{MSE}}\)</span>:</p>
</blockquote>
<ol style="list-style-type: decimal">
<li>First, calculate the Sum of Squares due to Error, <span class="math inline">\(\text{SSE}\)</span>:</li>
</ol>
<p><span class="math display">\[SSE = \sum_{j = 1}^{k}{(n_{j} - 1)(s_{j}^{2})}\]</span></p>
<p><span class="math display">\[{\text{where\ }n_{j} = the\ sample\ size\ of\ group\ j
}{s_{j}^{2} = the\ sample\ variance\ of\ group\ j
}{k = the\ number\ of\ groups}\]</span></p>
<blockquote>
<p>2) Second, use the <span class="math inline">\(\text{SSE}\)</span> to calculate the <span class="math inline">\(\text{MSE}\)</span>:</p>
</blockquote>
<p><span class="math display">\[MSE = \frac{\text{SSE}}{n_{T} - k}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><strong><span class="underline">Now calculate the test statistic,</span></strong>
<span class="math inline">\(\mathbf{F}_{\mathbf{\text{test}}}\)</span><strong><span class="underline">:</span></strong></li>
</ol>
<p><span class="math display">\[\mathbf{F}_{\mathbf{\text{test}}}\mathbf{=}\frac{\mathbf{\text{MSTR}}}{\mathbf{\text{MSE}}}\]</span></p>
<p><strong>with</strong></p>
<p><span class="math display">\[{\mathbf{numerator\ degrees\ of\ freedom = d}\mathbf{f}_{\mathbf{1}}\mathbf{= k - 1}
}{\mathbf{denominator\ degrees\ of\ freedom = d}\mathbf{f}_{\mathbf{2}}\mathbf{=}\mathbf{n}_{\mathbf{T}}\mathbf{- k}}\]</span></p>
<p>In the process of calculating the ANOVA test statistic, we organize all
of the results of our calculations into an ANOVA table. ANOVA tables may
be labeled with different terminology (e.g. the book uses different
labels than Excel) but the numbers always represent the same
calculations.</p>
<p><strong>ANOVA Summary Table: Equations</strong></p>
<table style="width:97%;">
<colgroup>
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th><ul>
<li>*Source
of
Vari</li>
</ul>
ation**</th>
<th><strong>Sum
of
Sq
uares</strong></th>
<th><strong>
Degrees
of
Fr
eedom</strong></th>
<th><strong>Mean
S
quare</strong></th>
<th><strong>F</strong></th>
<th><strong>p-
value</strong></th>
<th><strong>C
ritical
value
of F</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Treat
ments</strong></td>
<td><span class="math display">\[SST
R = \ \
sum_{j
= 1}^{k
}{n_{j}
\ (\ove
rline{x
_{j}} -
 \ \ove
rset{̿}{
\overli
ne{x}}}
)^{2}\]</span></td>
<td><span class="math display">\[df
_{1} =
k - 1\]</span></td>
<td><span class="math display">\[M
STR = \
 \frac{
\text{S
STR}}{k
 - 1}\]</span></td>
<td><span class="math display">\[F
_{\text
{test}}
 = \fra
c{\text
{MSTR}}
{\text{
MSE}}\]</span></td>
<td><p>Upper
tail</p>
<p>p-value
for</p>
<p><span class="math display">\[F_{
\text{t
est}}\]</span></p></td>
<td><span class="math display">\[F
_{\alph
a,UT}\]</span></td>
</tr>
<tr class="even">
<td><strong>
Error</strong></td>
<td>$
<span class="math inline">\(SSE = \sum_{j  = 1}^{ k}{(n_{ j} - 1) (s_{j}^ {2})}\)</span>$</td>
<td>$
<span class="math inline">\(df_{2}  = n_{T } - k\)</span>$</td>
<td><span class="math display">\[M
SE = \f
rac{\te
xt{SSE}
}{n_{T}
 - k}\]</span></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><strong>
Total</strong></td>
<td><span class="math display">\[SST
= SSTR
+ SSE\]</span></td>
<td><span class="math display">\[n_{T
} - 1\]</span></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>ANOVA Summary Table: Simplified</strong></p>
<table style="width:97%;">
<colgroup>
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th><ul>
<li>*Source
of
Vari</li>
</ul>
ation**</th>
<th><strong>Sum
of
Sq
uares</strong></th>
<th><strong>
Degrees
of
Fr
eedom</strong></th>
<th><strong>Mean
S
quare</strong></th>
<th><strong>F</strong></th>
<th><strong>p-
value</strong></th>
<th><strong>C
ritical
value
of F</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Treat
ments</strong></td>
<td>$
<span class="math inline">\(\text{
SSTR}\)</span>$</td>
<td>nu
merator
$
df_{1}$</td>
<td>$
<span class="math inline">\(\text{
MSTR}\)</span>$</td>
<td><span class="math display">\[F_{
\text{t
est}}\]</span></td>
<td><p>Upper
tail</p>
<p>p-value
for</p>
<p><span class="math display">\[F_{
\text{t
est}}\]</span></p></td>
<td><span class="math display">\[F
_{\alph
a,UT}\]</span></td>
</tr>
<tr class="even">
<td><strong>
Error</strong></td>
<td><span class="math display">\[\text
{SSE}\]</span></td>
<td>deno
minator
$
df_{2}$</td>
<td><span class="math display">\[\text
{MSE}\]</span></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><strong>
Total</strong></td>
<td><span class="math display">\[SST
= SSTR
+ SSE\]</span></td>
<td><span class="math display">\[n_{T
} - 1\]</span></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div id="exercise-anova" class="section level3 unnumbered" number="">
<h3>Exercise: ANOVA</h3>
<p><em>Exercise 1.</em> Let’s suppose that the grocery store from Chapter 13:
Handout #1 decided to perform the experiment. The objective of the
experiment is to see whether any one of the three different ad designs
causes people to buy more produce. The store randomly samples customers
from its database, and then randomly assigns 22 of those customers to
receive Weekly Ad A, 21 of the customers to receive Weekly Ad B, and 20
of the customers to receive Weekly Ad C. Weekly produce purchases by
each customer are tracked, and the sample mean and variance of weekly
produce spending for each group are calculated. For each group, the
weekly spending on produce is normally distributed, and the population
variances are assumed to be equal.</p>
<table style="width:100%;">
<colgroup>
<col width="5%" />
<col width="19%" />
<col width="16%" />
<col width="34%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th>j</th>
<th>Treatment</th>
<th><span class="math display">\[n_{j}\]</span></th>
<th><p>Sample Mean</p>
<span class="math display">\[{\overline{x}}_{j}\]</span></th>
<th><p>Sample Variance</p>
<span class="math display">\[{s_{j}}^{2}\]</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Weekly Ad A</td>
<td></td>
<td>25.11</td>
<td>9.21</td>
</tr>
<tr class="even">
<td>2</td>
<td>Weekly Ad B</td>
<td></td>
<td>28.51</td>
<td>10.05</td>
</tr>
<tr class="odd">
<td>3</td>
<td>Weekly Ad C</td>
<td></td>
<td>29.20</td>
<td>9.91</td>
</tr>
</tbody>
</table>
<p>Use ANOVA to test whether the means for the three treatment groups are
equal at an <span class="math inline">\(\alpha\  = \ 0.05\)</span> significance level. Use your results to
fill in the ANOVA table.</p>
<p><strong>ANOVA Table for Exercise 1: Grocery Store Ads</strong></p>
<table>
<thead>
<tr class="header">
<th align="left"><strong>Source of Variation</strong></th>
<th align="left"><strong>Sum of Squares</strong></th>
<th align="left"><strong>Degrees of Freedom</strong></th>
<th align="left"><strong>Mean Square</strong></th>
<th align="left"><strong>F</strong></th>
<th align="left"><strong>Critical value of F</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><strong>Treatments</strong></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"><strong>Error</strong></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left"><strong>Total</strong></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p><em><br />
</em></p>
<p><em>Exercise 2.</em> In a study with a fully randomized experimental design,
four treatments were applied to randomly assigned groups of experimental
units. The first treatment group had 12 experimental units, the second
treatment group had 9 experimental units, the third treatment group had
9 experimental units, and the fourth treatment group had 14 experimental
units.</p>
<p>Given the following ANOVA table, test whether the population means are
equal at the α = 0.01 significance level.</p>
<table>
<thead>
<tr class="header">
<th align="left"><strong>Source of Variation</strong></th>
<th align="left"><strong>Sum of Squares</strong></th>
<th align="left"><strong>Degrees of Freedom</strong></th>
<th align="left"><strong>Mean Square</strong></th>
<th align="left"><strong>F</strong></th>
<th align="left"><strong>Critical value of F</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><strong>Treatments</strong></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"><strong>Error</strong></td>
<td align="left">50</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left"><strong>Total</strong></td>
<td align="left">65</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="fishers-least-significant-difference-a-multiple-comparison-procedure" class="section level2 unnumbered" number="">
<h2>Fisher’s Least Significant Difference: a Multiple Comparison Procedure</h2>
<p>If the null hypothesis in an ANOVA is rejected, then you may conclude
that not all the population means are equal. However, ANOVA by itself
cannot tell you <em>which</em> of the means are different. It could be only one
group that has a different mean with the rest being equal, or two
groups, or all of the groups could have different means. ANOVA is silent
in that respect.</p>
<p>Consider the case where there are four groups in an ANOVA analysis, so
the null and alternative hypotheses are:</p>
<p><span class="math inline">\(H_{0}:\ \mu_{1} = \mu_{2} = \mu_{3} = \mu_{4}\)</span></p>
<p><span class="math inline">\(H_{A}:Not\ all\ the\ population\ means\ are\ equal\)</span></p>
<p>If the null is rejected, then the question becomes: which mean is not
equal to the others? Are they all different, or is only one or two
different from the others? This is where <em>multiple comparison
procedures</em> come in. Multiple comparison procedures are only used <span class="underline">after
ANOVA confirms a difference</span>, to find out which groups have
a different mean from the others.</p>
<p>Multiple comparison procedures test pairs of means, and you have to run
one test per pair. Mathematically, we need to ask:
<span class="math inline">\(\text{is\ }\mu_{1} \neq \mu_{2}?\ \text{is\ }\mu_{2} \neq \mu_{3}?\ \text{is\ }\mu_{3} \neq \mu_{4}?\)</span>
is
<span class="math inline">\(\mu_{1} \neq \mu_{3}?\ \text{is\ }\mu_{2} \neq \mu_{4}?\text{is}\ \mu_{1} \neq \mu_{4}?\ \ \)</span>Notice
how those questions look like alternative hypotheses in a two tailed
test? Well, that is exactly what they are used for in multiple
comparisons.</p>
<p>Fisher’s Least Significant Difference (Fisher’s LSD) procedure is
commonly used for multiple comparisons. Fisher’s LSD is a special type
of two-tailed t test.</p>
<p>There are three different methods to use Fisher’s LSD: a traditional t
test; a modified t test; and, a confidence interval. All three methods
will come to the same conclusion, because they are all different ways of
using the same information. All three ways are presented in this handout
and in 13.3 in the book, but in this class only <strong>METHOD 2</strong> will be
used on the homework and on exams.</p>
<p><strong><span class="underline"><em>Method 1</em>: <em>Fisher’s LSD as a series of traditional t
tests</em></span><em>:</em></strong></p>
<ol style="list-style-type: decimal">
<li><p>Take any two groups from the ANOVA (here they are labeled <span class="math inline">\(i\)</span> and
<span class="math inline">\(j\)</span> just to differentiate them). Set an <span class="math inline">\(\alpha\)</span> significance level.</p></li>
<li><p>The hypotheses are:</p></li>
</ol>
<blockquote>
<p><span class="math inline">\(H_{0}:\ \mu_{i} = \mu_{j}\)</span></p>
<p><span class="math inline">\(H_{A}:\ \mu_{i} \neq \mu_{j}\)</span></p>
</blockquote>
<ol start="3" style="list-style-type: decimal">
<li>The test statistic is:</li>
</ol>
<blockquote>
<p><span class="math inline">\(t_{\text{test}} = \frac{{\overline{x}}_{i}\  - \ {\overline{x}}_{j}}{\sqrt{\text{MSE}\left( \frac{1}{n_{i}}\  + \ \frac{1}{n_{j}} \right)}}\)</span></p>
</blockquote>
<p><span class="math display">\[\text{where\ }\]</span></p>
<blockquote>
<p><span class="math inline">\({\overline{x}}_{i} = the\ sample\ mean\ of\ group\ i\)</span></p>
</blockquote>
<p><span class="math display">\[{\overline{x}}_{j} = the\ sample\ mean\ of\ group\ j\]</span></p>
<p><span class="math display">\[MSE = Mean\ Square\ Error\ from\ the\ ANOVA\]</span></p>
<p><span class="math display">\[n_{j} = sample\ size\ of\ the\ j^{\text{th}}\text{\ group}\]</span></p>
<blockquote>
<p>and the degrees of freedom are <span class="math inline">\(df_{2} = n_{T} - k\)</span> from the ANOVA</p>
</blockquote>
<ol start="4" style="list-style-type: decimal">
<li><p>The rejection rules are:</p>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(p\text{-}value\ approach:\ Reject\ H_{0}\text{\ if\ }2T\ p\text{-}value \leq \ \alpha\)</span></p></li>
<li><p><span class="math inline">\(Critical\ Value\ approach:Reject\ H_{0}\text{\ if\ }t_{\text{test}} \leq - t_{\frac{\alpha}{2}}\text{\ or\ }t_{\text{test}} \geq t_{\frac{\alpha}{2}}\ \)</span></p></li>
</ol></li>
</ol>
<p><span class="math display">\[with\ df = n_{T}\ –k\]</span></p>
<p><span class="math display">\[n_{T} = total\ sample\ size,\ from\ the\ ANOVA\]</span></p>
<p><span class="math display">\[k = the\ number\ of\ groups\ in\ the\ ANOVA\]</span></p>
<blockquote>
<p>NOTE: the df here are the same df from the <span class="math inline">\(\text{MSE}\)</span> in the ANOVA</p>
</blockquote>
<ol start="5" style="list-style-type: decimal">
<li><p>If the null hypothesis is rejected, then the two group means
<span class="math inline">\(\mu_{i}\text{\ and\ }\mu_{j}\ \)</span>are different. If the null
hypothesis is not rejected, then there is no evidence that
<span class="math inline">\(\mu_{i}\text{\ and\ }\mu_{j}\ \)</span>are different.</p></li>
<li><p>Conduct one test for each possible pair of means from the ANOVA</p></li>
</ol>
<p><strong><em><span class="underline">Method 2: Fisher’s LSD as a series of modified t tests</span>:
(This is the one we will use in this course)</em></strong></p>
<p>Take any two groups from the ANOVA (here they are labeled <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>
just to differentiate them). Set an <span class="math inline">\(\alpha\)</span> significance level.</p>
<ol style="list-style-type: decimal">
<li>The hypotheses are:</li>
</ol>
<blockquote>
<p><span class="math inline">\(H_{0}:\ \mu_{i} = \mu_{j}\)</span></p>
<p><span class="math inline">\(H_{A}:\ \mu_{i} \neq \mu_{j}\)</span></p>
</blockquote>
<ol start="2" style="list-style-type: decimal">
<li>The test statistic is:</li>
</ol>
<blockquote>
<p><span class="math inline">\({\overline{x}}_{i}\  - \ {\overline{x}}_{j}\)</span></p>
<p><span class="math inline">\(\text{where}\)</span></p>
<p><span class="math inline">\({\overline{x}}_{i} = the\ sample\ mean\ of\ group\ i\)</span></p>
<p><span class="math inline">\({\overline{x}}_{j} = the\ sample\ mean\ of\ group\ j\)</span></p>
</blockquote>
<ol start="3" style="list-style-type: decimal">
<li>The Least Significant Difference is:</li>
</ol>
<blockquote>
<p><span class="math inline">\(LSD = t_{\alpha/2}\sqrt{\text{MSE}\left( \frac{1}{n_{i}}\  + \ \frac{1}{n_{j}} \right)}\text{\ where\ the\ }2T\ t_{\alpha/2}\text{\ Critical\ Value\ has\ }df_{2} = n_{T} - k\)</span></p>
</blockquote>
<p><span class="math display">\[\text{and}\]</span></p>
<p><span class="math display">\[{n_{i} = sample\ size\ of\ the\ i^{\text{th}}\text{\ group}
}{n_{j} = sample\ size\ of\ the\ j^{\text{th}}\text{\ group}
}{n_{T} = the\ total\ sample\ size\ from\ the\ ANOVA
}{k = the\ number\ of\ groups\ in\ the\ ANOVA}\]</span></p>
<p>and the rejection rule is:</p>
<blockquote>
<p><span class="math inline">\(\text{If\ }\left| {\overline{x}}_{i}\  - \ {\overline{x}}_{j} \right| \geq LSD\ then\ reject\ H_{0}\text{\ and\ accept\ }H_{A}\text{.\ }\)</span></p>
<p><span class="math inline">\(\text{If\ }\left| {\overline{x}}_{i}\  - \ {\overline{x}}_{j} \right| &lt; LSD\ then\ \text{do\ not}\text{\ reject\ }H_{0}\text{\ and\ conclude\ }H_{A}\text{\ is\ unsupported.\ \ \ }\)</span></p>
</blockquote>
<ol start="4" style="list-style-type: decimal">
<li><p>If the null hypothesis is rejected, then the two group means
<span class="math inline">\(\mu_{i}\text{\ and\ }\mu_{j}\)</span> are different. If the null hypothesis
is not rejected, then there is no evidence that
<span class="math inline">\(\mu_{i}\text{\ and\ }\mu_{j}\)</span> are different.</p></li>
<li><p>Conduct one test for each possible pair of means from the ANOVA.
Note that this method is very efficient to use for multiple
comparisons in balanced designs (i.e. those in which the groups are
all the same size). In balanced designs, you only have to compute
the LSD once because it will be the same no matter which two groups
you are testing. Then you can compute the difference between each
pair of means and compare the absolute value of each difference to
the LSD to see whether to reject the null. In unbalanced designs
(i.e. those in which the groups are not all the same size), you will
have to compute the LSD individually for each test.</p></li>
</ol>
<p><strong><em><span class="underline">Method 3: Fisher’s LSD as a series of confidence
intervals</span>:</em></strong></p>
<p>Take any two groups from the ANOVA (here they are labeled <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>
just to differentiate them). Set an α significance level.</p>
<ol style="list-style-type: decimal">
<li>The hypotheses are:</li>
</ol>
<blockquote>
<p><span class="math inline">\(H_{0}:\ \mu_{i} = \mu_{j}\)</span></p>
<p><span class="math inline">\(H_{A}:\ \mu_{i} \neq \mu_{j}\)</span></p>
</blockquote>
<ol start="2" style="list-style-type: decimal">
<li>Calculate a <span class="math inline">\(100\left( 1 - \alpha \right)\%\)</span> confidence interval for
the difference between <span class="math inline">\(\mu_{i}\text{\ and\ }\mu_{j}\)</span> using the
following equation:</li>
</ol>
<blockquote>
<p><span class="math inline">\({\overline{x}}_{i}\  - \ {\overline{x}}_{j}\  \pm LSD\ where\ \)</span></p>
<p><span class="math inline">\(LSD = t_{\frac{\alpha}{2}}\sqrt{\text{MSE}\left( \frac{1}{n_{i}}\  + \ \frac{1}{n_{j}} \right)}\ \ and\ the\ t\ critical\ value\ has\ df = n_{T} - k\)</span></p>
</blockquote>
<ol start="3" style="list-style-type: decimal">
<li>The rejection rule is:</li>
</ol>
<blockquote>
<p><span class="math inline">\(\text{Reject\ }H_{0}\text{\ if\ the\ confidence\ interval\ does\ not\ include\ zero.}\)</span></p>
</blockquote>
<ol start="4" style="list-style-type: decimal">
<li><p>If the null hypothesis is rejected, then the two group means
<span class="math inline">\(\mu_{i}\text{\ and\ }\mu_{j}\)</span> are different.</p></li>
<li><p>Conduct one test for each possible unique pair of means from the
ANOVA</p></li>
</ol>
<p><strong><span class="underline"><br />
</span></strong></p>
<p><em>Example.</em> We are going to use Fisher’s LSD to test the groups from the
Grocery Store Ad example on Ch 13: Handout #4.</p>
<p><em>Part 1.</em> Using Method 2, perform a Fisher’s LSD procedure to test
whether the population mean produce spending for the group that received
Ad A is different than Ad B. Use an <span class="math inline">\(\alpha = 0.05\)</span> significance level.
If you can confirm a difference between the means, which group spent
more on average?</p>
<p><em>Example, part 2:</em> Using Method 2, perform a Fisher’s LSD procedure to
test whether the population mean produce spending for the group that
received Ad A is different than Ad C. Use an <span class="math inline">\(\alpha = 0.05\)</span>
significance level. If you can confirm a difference between the means,
which group spent more on average?</p>
<p><em>Example, part 3:</em> Using Method 2, perform a Fisher’s LSD procedure to
test whether the population mean produce spending for the group that
received Ad B is different than Ad C. Use an <span class="math inline">\(\alpha = 0.05\)</span>
significance level. If you can confirm a difference between the means,
which group spent more on average?</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-12-tests-of-goodness-of-fit-and-independence.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-14-simple-linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true,
"info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
